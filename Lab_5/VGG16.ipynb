{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/smudge/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "#Load VGG16\n",
    "model=torch.hub.load(\"pytorch/vision:v0.10.0\",'vgg16',pretrained=True).to(device=torch.device(\"mps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib \n",
    "url,filename=(\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try:\n",
    "    urllib.URLopener().retrieve(url,filename)\n",
    "except:\n",
    "    urllib.request.urlretrieve(url,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5954e-07, 8.6963e-07, 3.3579e-06, 1.4176e-06, 7.8357e-07, 3.8235e-06,\n",
      "        1.8886e-06, 1.6391e-05, 3.1994e-04, 1.5129e-06, 6.9162e-08, 2.4575e-07,\n",
      "        1.2883e-07, 7.5854e-07, 2.3596e-07, 1.4258e-07, 4.2883e-07, 1.4515e-06,\n",
      "        1.5482e-06, 2.3834e-07, 3.5217e-07, 3.0630e-06, 8.2786e-06, 1.0615e-05,\n",
      "        5.2350e-07, 1.2371e-07, 3.6896e-07, 9.1417e-07, 2.3006e-07, 1.8979e-05,\n",
      "        3.6893e-08, 1.8162e-07, 1.1007e-07, 7.0543e-08, 1.0147e-07, 8.5124e-08,\n",
      "        2.1035e-07, 6.0134e-08, 1.0145e-07, 6.4196e-08, 2.2793e-07, 6.0636e-08,\n",
      "        2.4110e-08, 9.8594e-08, 1.2269e-07, 8.7662e-08, 1.0465e-06, 9.0854e-08,\n",
      "        7.5758e-08, 2.1450e-07, 7.6261e-07, 2.4479e-07, 2.8505e-07, 1.1023e-07,\n",
      "        1.1765e-07, 6.9962e-08, 8.1238e-08, 2.7698e-08, 1.9952e-07, 8.7179e-08,\n",
      "        4.1331e-07, 1.8523e-08, 1.5433e-08, 1.7431e-07, 1.3860e-07, 5.5003e-08,\n",
      "        1.5185e-07, 6.1531e-08, 3.6931e-08, 5.5518e-08, 9.3010e-07, 6.0937e-07,\n",
      "        1.5488e-07, 3.2249e-07, 2.4439e-07, 4.2146e-07, 1.2144e-07, 2.2564e-07,\n",
      "        4.6590e-05, 1.2207e-06, 3.5853e-06, 2.3021e-06, 3.6958e-07, 4.2441e-06,\n",
      "        6.1767e-06, 1.7067e-07, 3.6683e-07, 8.5648e-07, 4.0889e-08, 2.2450e-05,\n",
      "        4.7665e-08, 9.1789e-08, 3.2166e-08, 4.6762e-07, 3.7133e-07, 1.7821e-08,\n",
      "        2.8744e-07, 2.6088e-07, 2.5922e-07, 9.1162e-06, 1.2719e-06, 4.4044e-08,\n",
      "        3.3240e-07, 3.0444e-08, 1.3024e-02, 1.2797e-06, 1.4909e-05, 9.6908e-07,\n",
      "        2.5696e-06, 1.2406e-07, 2.4845e-06, 1.6401e-07, 3.6138e-06, 5.8882e-07,\n",
      "        1.0209e-06, 8.5006e-06, 5.0443e-08, 1.7276e-06, 8.1519e-08, 2.9735e-08,\n",
      "        3.4325e-08, 1.4671e-07, 8.5975e-08, 4.7967e-08, 8.5365e-07, 1.7837e-07,\n",
      "        1.7970e-06, 4.3221e-06, 3.0580e-07, 1.0848e-06, 4.5774e-07, 1.6601e-07,\n",
      "        8.3794e-06, 2.7321e-08, 5.9651e-07, 1.1541e-06, 2.1807e-07, 1.9362e-07,\n",
      "        8.7551e-07, 6.3111e-08, 1.6371e-07, 1.2640e-07, 8.5042e-08, 4.7803e-07,\n",
      "        2.3381e-06, 9.5166e-07, 6.5518e-06, 1.1801e-07, 7.6069e-07, 5.6558e-07,\n",
      "        7.9473e-08, 3.8614e-04, 7.0261e-04, 1.3841e-04, 5.6769e-04, 4.7433e-06,\n",
      "        5.3144e-06, 3.0681e-03, 9.9660e-06, 4.2966e-07, 6.4937e-06, 1.5816e-07,\n",
      "        4.5158e-07, 5.4982e-07, 1.4154e-07, 1.3432e-07, 2.7873e-07, 6.6233e-07,\n",
      "        6.9496e-07, 4.5063e-05, 2.5049e-06, 3.6479e-07, 6.1131e-07, 9.0931e-05,\n",
      "        5.1292e-05, 2.4634e-06, 6.5476e-07, 7.6829e-07, 1.1866e-07, 3.4951e-06,\n",
      "        2.5242e-06, 1.3429e-06, 4.1182e-06, 6.2824e-07, 3.8862e-06, 1.9466e-05,\n",
      "        1.7650e-04, 5.6739e-06, 3.6216e-05, 1.7410e-06, 6.9276e-05, 1.1986e-06,\n",
      "        2.6668e-05, 3.4967e-05, 1.0618e-05, 3.7765e-06, 2.5879e-06, 3.4313e-06,\n",
      "        3.5234e-07, 1.5438e-04, 7.5284e-05, 6.2987e-06, 3.5969e-06, 2.3862e-03,\n",
      "        1.3142e-05, 1.8699e-06, 1.9912e-07, 3.0682e-05, 7.1659e-06, 3.0745e-07,\n",
      "        9.4820e-08, 8.1200e-07, 1.0759e-05, 1.1836e-06, 9.5038e-07, 6.7919e-06,\n",
      "        1.8690e-05, 2.7308e-06, 2.9084e-06, 1.9748e-06, 4.5423e-06, 5.3810e-07,\n",
      "        6.3860e-04, 3.4498e-04, 1.3115e-04, 2.4920e-06, 1.2226e-05, 5.9040e-05,\n",
      "        4.6727e-05, 3.8538e-04, 5.2656e-04, 1.1003e-03, 4.8932e-04, 5.8597e-06,\n",
      "        1.1060e-06, 9.1345e-05, 2.4258e-06, 1.5927e-06, 3.5679e-06, 8.8132e-06,\n",
      "        5.1507e-06, 2.3118e-06, 1.3869e-06, 2.0870e-07, 6.6037e-06, 1.5826e-05,\n",
      "        1.8961e-06, 8.0195e-06, 7.7518e-03, 8.2565e-04, 1.5591e-03, 7.9579e-06,\n",
      "        3.4770e-06, 1.6191e-05, 1.0886e-06, 1.9129e-06, 1.1557e-05, 3.2647e-03,\n",
      "        7.6069e-01, 2.7540e-02, 9.2937e-04, 4.4411e-03, 3.4180e-06, 2.8051e-04,\n",
      "        9.1335e-05, 3.7510e-05, 1.2036e-05, 1.5746e-05, 3.7804e-07, 1.6469e-04,\n",
      "        1.6656e-02, 8.4839e-06, 3.3038e-05, 6.4089e-05, 6.4081e-05, 1.0191e-06,\n",
      "        5.3662e-06, 2.9968e-04, 1.3311e-04, 6.2089e-02, 1.5059e-04, 1.1539e-04,\n",
      "        5.0258e-05, 2.8884e-02, 2.2175e-04, 1.1138e-03, 1.2065e-06, 5.1547e-04,\n",
      "        7.6503e-07, 4.0063e-06, 3.1344e-07, 5.9339e-07, 1.2119e-06, 6.6037e-07,\n",
      "        1.4059e-06, 1.7988e-06, 4.0277e-05, 5.4878e-07, 1.0942e-06, 1.7064e-06,\n",
      "        1.2732e-07, 7.8347e-07, 1.6424e-07, 1.5087e-07, 4.8067e-07, 4.4792e-08,\n",
      "        2.3747e-07, 1.0929e-07, 1.2238e-07, 1.9642e-07, 1.0534e-06, 5.2834e-07,\n",
      "        1.9022e-06, 4.0504e-07, 1.3657e-06, 3.6286e-07, 4.2460e-08, 1.5875e-06,\n",
      "        1.4115e-06, 7.5405e-08, 6.1895e-08, 2.2211e-07, 5.6020e-07, 8.6528e-08,\n",
      "        1.9879e-06, 3.0481e-07, 1.7754e-07, 9.2668e-06, 1.1233e-06, 2.5358e-06,\n",
      "        5.3981e-04, 3.4130e-03, 4.0514e-02, 1.3671e-03, 2.4376e-05, 1.5328e-05,\n",
      "        1.4105e-06, 2.8996e-06, 5.7136e-05, 5.4153e-07, 3.0404e-07, 1.9135e-05,\n",
      "        8.3557e-07, 3.0733e-07, 1.2815e-07, 9.6437e-07, 7.9054e-08, 2.5550e-07,\n",
      "        6.5898e-06, 9.4147e-08, 2.7308e-07, 1.4231e-07, 3.4540e-07, 5.8211e-07,\n",
      "        9.0433e-08, 8.8192e-05, 2.4128e-04, 1.2867e-04, 3.8025e-04, 1.3987e-04,\n",
      "        3.1783e-07, 2.1426e-04, 1.3539e-06, 1.9665e-06, 4.4317e-08, 9.1533e-08,\n",
      "        1.0408e-07, 2.6834e-07, 2.6767e-06, 3.6878e-07, 1.5931e-06, 1.0948e-06,\n",
      "        1.0228e-06, 3.3059e-06, 2.0632e-06, 3.6252e-07, 1.2396e-07, 5.4880e-06,\n",
      "        3.2158e-06, 2.6179e-07, 6.2827e-06, 4.7809e-07, 1.0001e-06, 4.2829e-06,\n",
      "        6.4215e-06, 2.3903e-08, 2.4601e-08, 2.8367e-06, 6.6257e-06, 7.1532e-07,\n",
      "        3.2940e-08, 1.2860e-06, 2.2287e-07, 2.4465e-07, 7.6251e-07, 1.2199e-07,\n",
      "        2.0724e-07, 4.3799e-07, 4.8954e-07, 1.6527e-06, 1.2717e-06, 9.4484e-07,\n",
      "        1.3927e-06, 4.4653e-07, 8.0800e-06, 1.9801e-05, 2.2104e-06, 2.4939e-06,\n",
      "        5.7101e-06, 1.1006e-05, 9.8620e-08, 1.8587e-06, 4.2716e-05, 2.9392e-06,\n",
      "        8.6356e-07, 2.5235e-06, 3.2074e-07, 1.8690e-05, 3.8292e-06, 2.0000e-05,\n",
      "        3.0014e-06, 2.0739e-06, 6.6920e-07, 3.2787e-07, 4.8817e-07, 4.5418e-06,\n",
      "        2.4493e-06, 4.3833e-06, 5.8013e-05, 1.1370e-05, 3.5522e-07, 1.4878e-05,\n",
      "        1.6836e-06, 3.7807e-06, 1.4670e-05, 2.2019e-05, 1.0326e-06, 2.8725e-05,\n",
      "        1.0177e-05, 4.8775e-05, 6.3097e-06, 1.4944e-06, 2.7144e-05, 4.5803e-06,\n",
      "        1.7839e-07, 9.0468e-07, 4.3689e-06, 3.9861e-06, 2.0157e-06, 5.0910e-07,\n",
      "        2.0457e-05, 2.0322e-06, 5.4235e-06, 3.2584e-06, 2.9173e-06, 8.1354e-06,\n",
      "        9.2652e-06, 3.7022e-05, 3.2727e-07, 2.9578e-06, 2.5624e-05, 2.8444e-06,\n",
      "        6.3215e-05, 7.5167e-05, 1.6831e-06, 1.9507e-06, 3.9651e-06, 5.8909e-08,\n",
      "        3.7512e-06, 3.2370e-05, 5.3049e-04, 2.8703e-06, 1.1205e-06, 2.5058e-06,\n",
      "        7.9016e-07, 1.5550e-06, 1.6971e-06, 1.3636e-06, 1.6825e-04, 2.4626e-06,\n",
      "        1.7548e-06, 1.8164e-06, 2.3717e-07, 5.1228e-06, 1.0386e-05, 6.9677e-07,\n",
      "        9.9622e-07, 2.4625e-06, 3.5237e-07, 1.8230e-05, 4.9670e-07, 1.7841e-06,\n",
      "        3.0763e-06, 3.6583e-06, 2.2561e-06, 1.4539e-06, 1.6929e-05, 1.4207e-05,\n",
      "        3.9296e-06, 5.9126e-06, 1.0353e-07, 1.7172e-05, 7.4597e-06, 3.8081e-06,\n",
      "        4.3463e-06, 4.0420e-06, 8.1226e-07, 6.2749e-07, 1.7596e-05, 1.3027e-07,\n",
      "        2.7621e-06, 9.1496e-07, 8.8403e-07, 5.3577e-07, 1.7587e-06, 2.7160e-05,\n",
      "        8.7600e-06, 1.8958e-06, 3.1832e-06, 1.3663e-05, 1.6965e-05, 5.1670e-06,\n",
      "        1.5356e-05, 6.7082e-06, 2.0004e-06, 4.0978e-06, 4.0536e-06, 4.0109e-06,\n",
      "        1.9463e-07, 3.6849e-06, 5.5190e-06, 8.3167e-07, 7.7438e-06, 1.0302e-06,\n",
      "        1.8492e-05, 5.4214e-07, 2.1832e-06, 2.6967e-05, 4.8079e-06, 5.4141e-04,\n",
      "        2.5896e-06, 3.7074e-07, 5.9329e-06, 1.2830e-05, 5.8002e-07, 1.0252e-05,\n",
      "        9.0027e-06, 4.8791e-07, 7.7459e-07, 4.4918e-06, 5.8867e-07, 3.3328e-06,\n",
      "        6.5113e-05, 1.1432e-05, 7.0087e-05, 3.3445e-06, 1.8580e-05, 2.6090e-05,\n",
      "        8.1207e-06, 1.2996e-05, 4.7633e-06, 2.8196e-06, 1.3802e-05, 2.0110e-06,\n",
      "        1.7980e-06, 1.9583e-06, 3.8961e-07, 5.6906e-06, 6.7776e-05, 6.2628e-07,\n",
      "        1.8256e-06, 6.3072e-08, 1.8268e-06, 4.5451e-06, 2.2530e-05, 3.8538e-06,\n",
      "        7.4256e-07, 2.0390e-06, 3.7064e-05, 3.0424e-06, 5.3058e-06, 4.2265e-07,\n",
      "        4.3086e-07, 5.1650e-06, 5.3298e-06, 5.7230e-06, 4.8218e-07, 2.1857e-06,\n",
      "        3.4720e-05, 4.4939e-06, 1.6339e-06, 3.5015e-05, 4.2835e-07, 8.1035e-06,\n",
      "        2.9430e-06, 2.0825e-06, 7.5727e-06, 2.8506e-06, 1.0251e-06, 1.2029e-07,\n",
      "        8.1908e-06, 6.2074e-05, 3.9417e-06, 5.7137e-07, 2.6453e-06, 3.7635e-06,\n",
      "        1.9360e-05, 4.7053e-06, 1.4505e-05, 4.5374e-07, 1.1980e-06, 3.8615e-06,\n",
      "        6.3848e-08, 2.3903e-06, 6.5235e-06, 1.7700e-05, 2.8235e-07, 6.0472e-06,\n",
      "        2.8262e-06, 4.8384e-06, 1.9931e-05, 6.3749e-06, 1.4262e-05, 2.2806e-06,\n",
      "        9.1430e-07, 5.8157e-06, 3.8497e-05, 8.6831e-06, 8.4947e-06, 5.3364e-05,\n",
      "        1.3402e-06, 1.5024e-05, 4.4955e-06, 1.0104e-06, 5.5935e-07, 2.3374e-06,\n",
      "        2.8973e-06, 5.8988e-06, 2.0328e-06, 9.4520e-07, 7.9058e-06, 2.7152e-06,\n",
      "        3.4928e-06, 9.5644e-06, 7.5714e-06, 2.6536e-07, 2.5047e-06, 2.2976e-06,\n",
      "        2.2848e-06, 7.0178e-07, 2.0820e-06, 7.4823e-07, 9.3028e-07, 2.0238e-05,\n",
      "        5.4685e-07, 1.8713e-06, 1.7490e-06, 6.5474e-04, 1.1112e-05, 7.2493e-07,\n",
      "        8.7579e-07, 1.6974e-07, 1.0928e-05, 2.8579e-06, 1.1074e-05, 1.1645e-06,\n",
      "        1.1713e-06, 3.0798e-06, 4.6346e-06, 3.4380e-06, 4.3670e-06, 3.5031e-07,\n",
      "        1.3552e-06, 4.4845e-05, 1.4739e-05, 7.5309e-07, 1.5520e-04, 9.2211e-06,\n",
      "        3.9861e-06, 1.4857e-06, 1.1209e-04, 7.1787e-06, 2.0879e-06, 4.3391e-06,\n",
      "        8.0145e-06, 5.5179e-07, 9.9658e-07, 1.2904e-06, 1.3597e-06, 3.9389e-06,\n",
      "        1.1071e-07, 4.3137e-07, 2.3632e-06, 1.5037e-06, 1.0138e-05, 3.1706e-06,\n",
      "        4.1641e-06, 3.4803e-06, 2.5789e-06, 1.1128e-05, 2.1461e-04, 1.0652e-05,\n",
      "        7.6530e-07, 1.1243e-05, 5.2268e-06, 7.0638e-07, 3.7312e-06, 6.9890e-07,\n",
      "        8.8652e-06, 3.4425e-06, 5.2880e-06, 4.7177e-06, 4.1592e-06, 4.8498e-06,\n",
      "        1.2005e-06, 1.4712e-06, 1.4449e-05, 7.0287e-07, 7.0776e-06, 2.5974e-05,\n",
      "        3.2183e-06, 4.4839e-06, 6.8042e-05, 2.4620e-05, 9.0230e-07, 8.2358e-06,\n",
      "        2.6409e-07, 4.0263e-06, 5.1915e-05, 2.6302e-06, 9.5297e-07, 1.6355e-04,\n",
      "        1.7032e-07, 1.2494e-05, 2.0428e-07, 2.7967e-06, 4.8434e-06, 1.0694e-06,\n",
      "        4.4435e-06, 8.8756e-08, 9.3640e-07, 5.4991e-06, 2.9429e-05, 3.5624e-06,\n",
      "        6.0863e-04, 1.3918e-06, 9.8471e-06, 3.7302e-06, 5.3832e-06, 3.9452e-05,\n",
      "        1.6285e-05, 5.5064e-06, 7.4259e-07, 7.0456e-05, 2.6106e-06, 1.2077e-06,\n",
      "        1.9424e-05, 1.1335e-06, 7.8616e-07, 6.5877e-07, 9.4265e-06, 3.8240e-05,\n",
      "        5.9771e-07, 9.3226e-07, 5.4513e-06, 2.3315e-05, 3.1855e-07, 8.2924e-06,\n",
      "        6.6562e-06, 2.5563e-05, 1.2674e-06, 5.1856e-07, 7.0463e-06, 8.4726e-05,\n",
      "        6.4724e-07, 3.4450e-07, 5.0451e-07, 2.2642e-06, 6.0356e-06, 6.8784e-07,\n",
      "        1.0100e-05, 2.1834e-06, 6.0334e-06, 7.6019e-06, 8.5155e-06, 5.1040e-06,\n",
      "        1.6671e-06, 7.6172e-07, 2.9627e-06, 4.6848e-05, 1.0918e-05, 2.8341e-06,\n",
      "        1.6718e-05, 5.0692e-06, 2.9845e-05, 1.1966e-05, 1.9745e-06, 2.2622e-05,\n",
      "        1.3917e-06, 4.3325e-05, 1.3271e-06, 1.5398e-07, 4.8631e-06, 7.0179e-06,\n",
      "        1.9276e-05, 7.7463e-06, 1.6141e-05, 2.2450e-05, 9.8192e-07, 1.8109e-06,\n",
      "        2.6346e-06, 1.1050e-04, 2.4471e-05, 1.9848e-05, 2.2808e-05, 4.0087e-07,\n",
      "        4.2959e-06, 3.4126e-06, 6.6960e-05, 6.3278e-06, 3.0881e-06, 7.6097e-07,\n",
      "        5.1354e-07, 4.1367e-06, 1.0351e-05, 4.6213e-07, 1.7257e-06, 7.2939e-06,\n",
      "        6.8256e-06, 7.9177e-07, 3.8070e-06, 1.9514e-05, 1.4858e-05, 9.0571e-06,\n",
      "        3.4010e-06, 1.1050e-06, 1.2532e-06, 2.2907e-06, 6.3647e-06, 3.1845e-06,\n",
      "        3.2024e-05, 4.7554e-06, 4.2487e-06, 3.4440e-06, 1.9015e-05, 4.2970e-05,\n",
      "        7.9396e-06, 1.7438e-06, 5.0848e-07, 3.7275e-06, 2.5772e-05, 1.2469e-05,\n",
      "        2.2585e-04, 1.5847e-07, 5.6282e-06, 1.1729e-05, 2.5078e-07, 5.3957e-07,\n",
      "        4.9618e-06, 1.0217e-06, 5.2827e-07, 3.8137e-05, 1.9277e-05, 4.1097e-07,\n",
      "        3.2251e-06, 1.6810e-06, 1.9595e-06, 1.2935e-05, 9.2182e-07, 5.2733e-06,\n",
      "        6.2900e-06, 6.0360e-06, 2.2562e-06, 8.0416e-07, 4.8674e-07, 8.7936e-07,\n",
      "        4.7151e-05, 4.0128e-06, 2.3219e-07, 3.1773e-05, 5.8716e-06, 8.7221e-07,\n",
      "        6.9091e-06, 5.7132e-06, 2.7214e-06, 1.4336e-05, 2.1872e-06, 1.7354e-06,\n",
      "        1.7687e-06, 1.0425e-06, 1.7760e-06, 2.8179e-06, 5.3975e-06, 9.3756e-07,\n",
      "        1.3326e-05, 5.4910e-06, 7.7860e-06, 3.4571e-06, 3.2993e-06, 8.2926e-06,\n",
      "        8.3438e-06, 9.0447e-07, 1.0512e-05, 2.3445e-06, 6.3809e-04, 4.3340e-05,\n",
      "        2.0008e-06, 3.7078e-06, 1.5587e-05, 2.6214e-05, 3.5872e-06, 1.4153e-05,\n",
      "        1.5641e-05, 3.4595e-06, 1.0474e-05, 1.5275e-06, 4.1211e-06, 9.7145e-07,\n",
      "        9.6156e-06, 2.3165e-06, 2.5582e-06, 4.8819e-06, 2.8334e-07, 5.6430e-07,\n",
      "        1.1126e-07, 5.8671e-07, 4.8792e-07, 1.1862e-06, 1.4305e-06, 6.4262e-05,\n",
      "        9.5229e-08, 6.8086e-07, 5.0287e-07, 1.5649e-07, 6.1768e-07, 9.9005e-06,\n",
      "        1.7494e-06, 2.1688e-04, 3.8190e-07, 1.1617e-06, 2.5437e-06, 1.8791e-07,\n",
      "        6.4698e-06, 2.9977e-06, 7.0429e-08, 3.0234e-07, 5.2905e-07, 1.4054e-06,\n",
      "        3.8689e-06, 2.8521e-06, 1.1313e-06, 3.6480e-07, 1.7798e-07, 6.2792e-06,\n",
      "        2.4424e-06, 4.1733e-07, 1.5642e-06, 1.2634e-06, 1.4955e-05, 5.1827e-07,\n",
      "        4.7252e-07, 1.1582e-06, 1.1482e-07, 2.0783e-07, 3.0388e-07, 1.5756e-07,\n",
      "        1.3218e-06, 2.6646e-06, 5.8039e-06, 9.0285e-06, 3.4074e-06, 5.5455e-06,\n",
      "        1.1067e-06, 2.6857e-07, 1.7784e-05, 1.4704e-05, 1.2784e-06, 2.7812e-05,\n",
      "        4.9887e-06, 1.6254e-06, 4.9487e-07, 3.4521e-06, 1.0017e-05, 2.3633e-07,\n",
      "        1.7256e-06, 2.2162e-06, 5.4989e-08, 1.1331e-05, 9.6027e-07, 2.1766e-06,\n",
      "        4.0998e-07, 7.2037e-07, 2.8133e-06, 4.8760e-08, 3.8927e-08, 9.1238e-07,\n",
      "        3.5063e-07, 3.2163e-08, 7.7262e-06, 3.2571e-05], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "input_image=Image.open(filename)\n",
    "preprocess=T.Compose([\n",
    "    T.Resize((256,256)),T.CenterCrop(224),T.ToTensor(),T.Normalize((0.5,0.5,0.5),(1,1,1))\n",
    "])\n",
    "\n",
    "input_tensor=preprocess(input_image)\n",
    "input_batch=input_tensor.unsqueeze(0).to(device=torch.device(\"mps\"))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output=model(input_batch)\n",
    "\n",
    "probabs=torch.nn.functional.softmax(output[0],dim=0)\n",
    "print(probabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samoyed 0.7606880068778992\n",
      "Arctic fox 0.06208876520395279\n",
      "Angora 0.04051428660750389\n",
      "Persian cat 0.028883982449769974\n",
      "Pomeranian 0.027540134266018867\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"imagenet_classes.txt\",\"r\") as f:\n",
    "    categories=[s.strip() for s in f.readlines()]\n",
    "\n",
    "top5_probab,top5_catid=torch.topk(probabs,5)\n",
    "\n",
    "for i in range(top5_probab.size(0)):\n",
    "     print(categories[top5_catid[i]], top5_probab[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
