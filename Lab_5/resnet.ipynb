{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/smudge/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /Users/smudge/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:09<00:00, 10.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "#Load Reset50\n",
    "model=torch.hub.load(\"pytorch/vision:v0.10.0\",'resnet50',pretrained=True).to(device=torch.device(\"mps\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib \n",
    "url,filename=(\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try:\n",
    "    urllib.URLopener().retrieve(url,filename)\n",
    "except:\n",
    "    urllib.request.urlretrieve(url,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.5074e-07, 8.0297e-08, 1.8022e-07, 4.6474e-07, 1.2111e-07, 2.3057e-06,\n",
      "        1.3924e-06, 2.4499e-06, 2.6772e-05, 4.1596e-07, 1.6536e-08, 3.4455e-08,\n",
      "        2.8999e-08, 2.2331e-08, 1.4412e-08, 6.6677e-08, 1.2554e-07, 1.4329e-07,\n",
      "        1.7138e-07, 4.5309e-08, 1.1789e-07, 7.3758e-07, 4.0848e-07, 1.4189e-06,\n",
      "        1.7198e-07, 9.6020e-08, 5.7924e-07, 2.7109e-07, 4.0514e-08, 1.5290e-06,\n",
      "        1.3665e-07, 1.9455e-07, 4.1429e-07, 2.6003e-08, 6.2344e-08, 6.5738e-08,\n",
      "        1.3307e-07, 2.2077e-08, 1.1097e-07, 8.8358e-08, 2.8000e-07, 3.4226e-08,\n",
      "        6.2703e-08, 1.1356e-07, 1.9303e-06, 7.3314e-08, 1.2218e-07, 2.5330e-07,\n",
      "        4.0829e-08, 5.4732e-07, 1.5716e-06, 2.8976e-07, 1.7868e-07, 3.9312e-07,\n",
      "        6.4412e-08, 2.0876e-08, 1.1273e-08, 6.1270e-08, 1.8218e-06, 1.4285e-07,\n",
      "        4.7240e-07, 9.0485e-09, 1.4980e-08, 4.7792e-08, 1.5340e-08, 2.5455e-08,\n",
      "        3.5787e-07, 3.3582e-07, 1.7927e-07, 7.7482e-09, 1.3383e-07, 8.9468e-08,\n",
      "        4.6812e-08, 5.0334e-08, 4.2999e-08, 5.8717e-08, 1.1466e-08, 7.9205e-08,\n",
      "        6.7216e-07, 4.7779e-08, 4.4502e-07, 4.3854e-07, 1.0062e-06, 9.7655e-07,\n",
      "        8.5216e-08, 6.7754e-08, 3.7285e-07, 5.9419e-08, 2.3038e-08, 1.6686e-06,\n",
      "        2.2761e-08, 4.6471e-08, 1.7634e-08, 8.4218e-08, 9.3906e-08, 1.3141e-08,\n",
      "        1.2216e-08, 7.6446e-09, 2.6611e-08, 5.1627e-07, 5.0032e-07, 2.7378e-07,\n",
      "        3.3435e-07, 9.0154e-08, 7.9017e-05, 1.5831e-07, 6.8717e-07, 2.9921e-08,\n",
      "        1.2172e-07, 6.4385e-09, 5.6397e-08, 6.4669e-09, 3.1844e-07, 1.7451e-07,\n",
      "        6.9236e-08, 7.9006e-08, 3.4034e-08, 9.6067e-08, 1.2826e-07, 4.7752e-08,\n",
      "        6.3122e-08, 3.1165e-08, 3.9271e-08, 4.8768e-08, 9.4576e-08, 4.9700e-08,\n",
      "        2.9955e-07, 2.4477e-06, 1.6536e-07, 6.3332e-07, 8.9632e-08, 5.5485e-08,\n",
      "        7.1496e-07, 4.2205e-08, 1.0886e-07, 4.8567e-07, 3.8260e-08, 3.1266e-08,\n",
      "        7.6507e-08, 2.4329e-09, 1.5977e-08, 1.0440e-07, 4.4960e-08, 4.0589e-08,\n",
      "        2.4658e-07, 6.7012e-08, 1.3094e-07, 4.9984e-08, 4.7672e-08, 6.0873e-07,\n",
      "        3.0386e-08, 5.7488e-05, 1.1535e-03, 7.0014e-05, 1.1370e-03, 3.6428e-06,\n",
      "        1.9219e-06, 3.8767e-04, 2.7193e-06, 6.7928e-07, 2.4476e-07, 4.6900e-08,\n",
      "        2.1186e-08, 9.0647e-08, 5.4308e-08, 4.0588e-08, 5.2275e-08, 8.7494e-09,\n",
      "        9.3129e-08, 5.5203e-06, 2.4987e-07, 4.6251e-08, 1.9938e-08, 3.9988e-07,\n",
      "        3.7680e-06, 3.1825e-07, 1.0446e-07, 2.1176e-07, 5.7679e-08, 6.6946e-07,\n",
      "        2.1895e-07, 1.0188e-07, 1.2175e-07, 4.8624e-07, 2.9238e-07, 7.4607e-06,\n",
      "        1.8809e-05, 9.0604e-07, 3.2812e-06, 1.0334e-07, 3.3533e-06, 4.6977e-08,\n",
      "        1.4085e-05, 9.2871e-06, 6.6259e-07, 5.5843e-07, 4.7165e-08, 8.7901e-08,\n",
      "        3.1463e-08, 3.0381e-05, 1.3748e-05, 3.0169e-07, 2.2915e-07, 4.7038e-04,\n",
      "        4.0103e-06, 1.9217e-07, 8.2522e-08, 1.0299e-05, 7.7777e-07, 1.2207e-07,\n",
      "        4.4470e-08, 4.7877e-07, 9.5061e-07, 3.3401e-07, 2.6617e-07, 1.1708e-06,\n",
      "        2.9599e-05, 4.5626e-07, 6.5650e-07, 1.8697e-07, 5.2014e-06, 1.2969e-07,\n",
      "        5.7289e-04, 7.5360e-05, 2.8672e-04, 3.5209e-07, 8.3393e-06, 9.4719e-07,\n",
      "        5.9477e-05, 2.1366e-05, 5.3567e-05, 1.5142e-04, 4.3205e-05, 1.9359e-06,\n",
      "        2.0440e-07, 1.8744e-05, 4.8720e-07, 1.1488e-06, 1.3419e-07, 1.1020e-06,\n",
      "        3.0619e-07, 3.6352e-07, 6.8903e-07, 1.5272e-07, 4.2819e-06, 5.7056e-07,\n",
      "        1.0423e-07, 1.7569e-06, 1.0606e-04, 5.0570e-05, 1.6265e-05, 1.4626e-07,\n",
      "        2.5584e-06, 4.8262e-07, 1.0380e-06, 1.5771e-06, 2.8953e-05, 2.2561e-03,\n",
      "        9.2385e-01, 4.5759e-02, 2.6569e-03, 7.9454e-03, 4.2082e-06, 4.5213e-06,\n",
      "        1.2932e-06, 1.7126e-05, 1.1060e-06, 4.6230e-06, 7.8201e-08, 7.1746e-06,\n",
      "        8.3119e-04, 6.1507e-07, 2.2365e-06, 4.0755e-06, 2.8299e-05, 2.9414e-08,\n",
      "        3.6599e-07, 5.6063e-06, 2.9032e-06, 9.2199e-04, 6.1022e-06, 8.3983e-06,\n",
      "        2.1422e-06, 6.5824e-03, 1.9754e-06, 4.7927e-06, 8.7499e-08, 2.1548e-05,\n",
      "        4.0575e-07, 4.3450e-07, 1.0354e-07, 5.9364e-06, 1.6804e-06, 1.0035e-06,\n",
      "        2.0310e-07, 1.0817e-07, 7.3999e-07, 3.2465e-07, 2.2267e-07, 2.1328e-07,\n",
      "        4.1563e-09, 8.1591e-09, 2.0440e-08, 1.4016e-08, 8.1934e-09, 9.9452e-09,\n",
      "        6.2212e-08, 4.7651e-08, 8.5764e-09, 3.9343e-08, 1.6915e-07, 1.2526e-08,\n",
      "        4.8429e-08, 2.9226e-08, 3.4737e-07, 3.5344e-09, 1.1454e-08, 1.4298e-08,\n",
      "        1.6381e-08, 4.7548e-09, 2.5851e-08, 1.4845e-08, 2.9894e-08, 1.8254e-08,\n",
      "        3.1386e-08, 7.5251e-08, 3.9909e-08, 2.4717e-07, 9.1454e-08, 2.8429e-08,\n",
      "        4.1322e-06, 9.3530e-05, 3.3249e-03, 1.4571e-06, 6.1226e-07, 1.1722e-06,\n",
      "        1.3675e-07, 2.1354e-07, 5.3029e-07, 4.9552e-07, 5.2510e-07, 3.2390e-07,\n",
      "        1.0902e-07, 1.0404e-07, 1.7887e-07, 1.2510e-06, 4.2547e-07, 7.0184e-07,\n",
      "        1.9987e-06, 7.0501e-08, 8.5392e-08, 2.2739e-07, 2.4682e-07, 4.0578e-07,\n",
      "        1.2381e-07, 4.4222e-06, 8.4931e-07, 1.5490e-06, 3.6995e-06, 8.7442e-07,\n",
      "        2.1787e-08, 5.8762e-06, 7.5591e-08, 2.5789e-06, 1.9459e-08, 1.5912e-07,\n",
      "        3.4862e-08, 5.8365e-08, 3.2074e-07, 1.0715e-07, 1.3528e-07, 7.2578e-07,\n",
      "        1.3463e-07, 2.8782e-06, 3.5439e-07, 1.7116e-08, 9.1866e-09, 4.2305e-06,\n",
      "        1.4384e-07, 1.1812e-07, 1.3887e-06, 1.0224e-07, 1.7859e-07, 1.2409e-07,\n",
      "        1.1160e-06, 5.2619e-08, 1.1309e-08, 9.9865e-08, 3.9263e-08, 6.4518e-07,\n",
      "        2.2811e-08, 4.1729e-07, 2.7920e-08, 5.3344e-09, 2.4582e-07, 1.2012e-07,\n",
      "        4.4151e-08, 1.6239e-08, 6.8832e-08, 2.7965e-07, 4.4318e-08, 2.7468e-08,\n",
      "        4.9486e-08, 2.7875e-08, 2.8498e-08, 2.9725e-06, 1.0407e-07, 6.0191e-08,\n",
      "        6.0360e-06, 8.9823e-07, 7.5233e-09, 7.2510e-08, 1.4712e-06, 5.4784e-07,\n",
      "        9.6514e-08, 3.6532e-08, 1.0758e-08, 1.2034e-06, 1.7800e-07, 4.0116e-07,\n",
      "        1.0876e-07, 2.0762e-07, 4.2556e-07, 6.0557e-09, 5.6923e-09, 1.1537e-06,\n",
      "        3.4719e-07, 1.3543e-06, 1.4502e-06, 1.2387e-06, 5.4363e-08, 5.8872e-07,\n",
      "        3.3146e-08, 2.2626e-08, 1.1893e-07, 6.2633e-06, 3.1866e-07, 1.8902e-07,\n",
      "        1.1167e-07, 4.2406e-07, 5.6204e-08, 4.6682e-08, 2.3515e-07, 3.2550e-08,\n",
      "        6.7750e-08, 3.3225e-07, 2.5858e-07, 7.7564e-07, 4.2092e-08, 1.9511e-07,\n",
      "        5.5156e-07, 5.7513e-08, 5.0265e-07, 2.6762e-07, 4.0757e-08, 1.0574e-07,\n",
      "        3.3132e-07, 1.9300e-06, 2.2052e-07, 6.5025e-07, 9.8574e-07, 2.9581e-07,\n",
      "        9.0648e-06, 7.3408e-06, 1.1692e-07, 3.0371e-07, 2.9081e-08, 7.4339e-09,\n",
      "        3.1256e-07, 6.2053e-06, 2.7172e-06, 1.5254e-06, 1.0992e-06, 9.1264e-08,\n",
      "        1.3479e-08, 3.3817e-07, 1.7850e-07, 8.5275e-08, 6.0817e-06, 5.6222e-06,\n",
      "        1.1326e-06, 1.2515e-07, 2.0697e-08, 9.7679e-07, 1.4644e-07, 2.4017e-07,\n",
      "        4.5096e-08, 8.1664e-07, 2.7353e-06, 6.0854e-07, 5.6397e-08, 2.2734e-08,\n",
      "        1.0713e-07, 3.6959e-07, 7.8428e-08, 1.0478e-07, 9.8736e-08, 1.6493e-07,\n",
      "        1.8333e-08, 9.2996e-08, 2.1782e-08, 1.6194e-06, 9.7637e-08, 3.7652e-08,\n",
      "        1.8605e-07, 9.5868e-08, 4.0344e-08, 1.7022e-06, 8.8761e-07, 8.9861e-09,\n",
      "        8.5881e-08, 1.1265e-06, 1.3545e-07, 3.8801e-08, 7.8652e-08, 9.1318e-07,\n",
      "        7.3099e-07, 2.2195e-07, 1.8377e-07, 4.4554e-07, 3.0610e-07, 1.1584e-07,\n",
      "        9.6952e-07, 8.1981e-07, 7.9447e-08, 2.8546e-07, 1.8513e-07, 2.7644e-07,\n",
      "        6.8848e-07, 5.3401e-07, 1.5396e-07, 4.4856e-08, 1.1003e-07, 6.0747e-08,\n",
      "        2.9205e-06, 3.0583e-07, 2.1402e-08, 7.9075e-07, 3.2068e-08, 3.1284e-06,\n",
      "        1.1303e-07, 4.0467e-08, 5.4687e-08, 8.3615e-07, 4.9745e-07, 3.9320e-07,\n",
      "        1.1238e-07, 5.9803e-10, 6.4563e-08, 4.9319e-07, 8.5460e-09, 8.7323e-08,\n",
      "        4.4695e-06, 1.4332e-06, 4.5769e-07, 1.0751e-07, 4.0117e-07, 1.2228e-06,\n",
      "        8.2124e-08, 3.5843e-07, 1.6103e-07, 1.5621e-06, 1.1232e-07, 6.7976e-08,\n",
      "        2.0520e-07, 8.4805e-08, 6.5424e-08, 5.1113e-08, 8.9176e-07, 2.3109e-07,\n",
      "        1.2933e-07, 1.8743e-07, 8.6303e-07, 1.0537e-07, 4.5788e-05, 1.6649e-06,\n",
      "        1.4334e-07, 1.3282e-07, 2.0698e-06, 5.2780e-08, 3.5097e-07, 5.3652e-07,\n",
      "        4.8409e-08, 4.2634e-07, 2.3072e-07, 5.5377e-08, 6.4501e-07, 2.5186e-07,\n",
      "        4.4503e-07, 1.7242e-07, 5.2166e-07, 4.8979e-07, 5.8696e-08, 8.8609e-08,\n",
      "        4.0656e-07, 8.8394e-08, 2.5840e-06, 2.0424e-07, 1.3264e-07, 4.2912e-08,\n",
      "        1.2451e-06, 8.8486e-07, 9.3557e-08, 1.2399e-07, 1.6329e-07, 1.0394e-07,\n",
      "        9.1091e-07, 6.1594e-07, 3.0402e-07, 5.8394e-08, 3.1418e-08, 2.8830e-07,\n",
      "        3.2622e-08, 2.4444e-07, 3.8014e-07, 1.5748e-07, 1.5611e-07, 1.4642e-07,\n",
      "        8.7863e-07, 1.8391e-07, 1.9706e-07, 6.6304e-06, 2.0085e-06, 9.5094e-07,\n",
      "        8.8405e-08, 3.3375e-07, 2.1276e-07, 2.6547e-07, 1.1896e-07, 6.4536e-07,\n",
      "        2.3078e-07, 2.7838e-07, 1.9506e-07, 2.7563e-07, 5.2790e-08, 6.6570e-07,\n",
      "        5.4592e-07, 2.2920e-06, 6.9349e-08, 5.0921e-08, 7.4259e-07, 7.7366e-08,\n",
      "        2.1190e-08, 6.6141e-07, 1.4152e-06, 5.1743e-08, 2.5493e-06, 8.4882e-08,\n",
      "        1.0669e-07, 1.3973e-07, 1.5945e-07, 1.6816e-08, 2.3736e-07, 1.8737e-06,\n",
      "        4.3761e-08, 1.0948e-07, 7.8121e-07, 1.9202e-06, 7.6088e-08, 2.1041e-07,\n",
      "        3.4831e-07, 3.9847e-08, 2.4120e-07, 7.1834e-08, 1.0012e-06, 1.5966e-07,\n",
      "        2.4861e-07, 4.0676e-07, 2.6666e-08, 1.3977e-07, 4.2648e-07, 3.0210e-07,\n",
      "        2.2703e-07, 5.2940e-07, 1.0744e-06, 1.5411e-07, 8.9840e-06, 6.6103e-07,\n",
      "        1.2550e-07, 1.9204e-08, 7.4985e-07, 1.0958e-06, 2.8608e-08, 2.7051e-08,\n",
      "        4.3013e-08, 3.1700e-07, 1.0863e-07, 3.3013e-08, 7.0496e-08, 1.3651e-07,\n",
      "        2.0296e-07, 3.6667e-08, 3.7800e-07, 5.7290e-07, 1.0475e-06, 1.8796e-06,\n",
      "        3.5080e-07, 7.4833e-08, 2.9583e-07, 2.3362e-07, 1.9261e-06, 1.9801e-07,\n",
      "        1.1323e-08, 4.7509e-07, 9.8362e-08, 2.0407e-08, 8.6349e-08, 3.3538e-07,\n",
      "        3.6094e-07, 2.0141e-08, 8.5635e-08, 1.2818e-06, 7.4844e-07, 2.5760e-07,\n",
      "        2.9507e-07, 1.4422e-08, 1.6159e-06, 1.2046e-07, 6.9412e-07, 1.8399e-06,\n",
      "        6.7299e-08, 8.7420e-08, 2.0403e-06, 1.9250e-06, 1.8211e-07, 8.1141e-08,\n",
      "        5.0163e-09, 1.7939e-07, 2.5231e-06, 1.6458e-07, 7.8502e-07, 1.7103e-06,\n",
      "        2.2125e-08, 6.6643e-07, 7.8011e-09, 5.9389e-07, 6.6166e-08, 4.1936e-08,\n",
      "        9.2985e-08, 1.4978e-08, 5.9951e-08, 1.0281e-07, 7.6707e-07, 4.6274e-07,\n",
      "        1.8004e-06, 1.4949e-07, 7.9495e-07, 7.3095e-08, 3.4694e-06, 1.1992e-06,\n",
      "        1.3255e-06, 1.8437e-06, 2.7437e-07, 1.0526e-06, 7.3638e-07, 1.6567e-06,\n",
      "        2.4121e-06, 7.5039e-08, 3.0601e-07, 1.2627e-07, 1.2162e-06, 3.1760e-06,\n",
      "        2.6846e-08, 2.3414e-07, 2.9850e-06, 6.3451e-07, 5.6746e-08, 6.7991e-08,\n",
      "        5.3399e-07, 2.9049e-07, 1.6231e-07, 2.5430e-06, 2.3701e-06, 2.7525e-07,\n",
      "        2.3455e-08, 1.0242e-07, 2.5151e-08, 7.7388e-08, 5.8952e-07, 1.5630e-08,\n",
      "        7.3780e-07, 1.3365e-07, 1.6003e-06, 3.1294e-06, 2.4028e-07, 6.2521e-07,\n",
      "        1.8537e-07, 1.8201e-06, 1.6251e-07, 4.6048e-07, 2.8595e-07, 8.9431e-07,\n",
      "        7.5453e-06, 3.3253e-07, 9.8804e-07, 5.1540e-08, 3.6010e-08, 3.5820e-07,\n",
      "        6.9272e-08, 2.7153e-07, 7.6204e-08, 1.4834e-08, 2.3721e-07, 1.2322e-07,\n",
      "        2.1974e-07, 1.4694e-06, 6.5451e-08, 7.9472e-07, 8.7001e-08, 8.7108e-08,\n",
      "        3.8023e-07, 1.4015e-06, 7.3615e-08, 2.2234e-07, 1.1801e-06, 4.1194e-07,\n",
      "        4.4690e-08, 1.3310e-06, 8.3663e-07, 8.7460e-08, 4.6462e-07, 8.4745e-08,\n",
      "        6.2633e-08, 2.9511e-07, 5.9873e-08, 2.1561e-07, 8.4693e-06, 4.3687e-07,\n",
      "        4.8133e-07, 6.6867e-09, 2.3580e-08, 4.9255e-07, 1.2535e-07, 6.3988e-07,\n",
      "        2.1259e-07, 2.0708e-07, 1.3429e-07, 6.4687e-07, 2.8142e-07, 2.6415e-07,\n",
      "        9.2711e-07, 1.2486e-07, 2.2337e-07, 5.7968e-07, 3.9149e-06, 1.8869e-07,\n",
      "        1.8360e-07, 4.8800e-07, 5.0595e-08, 1.5403e-07, 1.4500e-06, 4.3632e-07,\n",
      "        2.1374e-05, 3.5314e-08, 2.5578e-07, 8.2835e-07, 4.3820e-08, 3.5869e-08,\n",
      "        9.3255e-08, 5.1036e-08, 5.2661e-08, 9.1613e-07, 2.1057e-07, 1.8837e-08,\n",
      "        3.1030e-07, 3.8367e-07, 3.2293e-07, 1.5608e-06, 1.1294e-07, 8.2383e-07,\n",
      "        3.5648e-07, 2.0299e-07, 9.0268e-07, 5.4253e-08, 2.9764e-09, 6.2938e-08,\n",
      "        2.3638e-05, 4.5808e-08, 2.0491e-07, 1.7162e-06, 1.8881e-06, 7.3620e-08,\n",
      "        1.3789e-06, 1.4569e-07, 1.8365e-07, 1.6915e-07, 1.9736e-07, 4.9359e-09,\n",
      "        1.5322e-07, 2.9744e-08, 2.9223e-08, 1.3271e-07, 1.1858e-06, 9.6932e-08,\n",
      "        1.3656e-07, 1.8692e-07, 1.4768e-06, 7.5911e-07, 3.4829e-07, 1.8534e-07,\n",
      "        7.4465e-07, 3.4600e-07, 4.5029e-06, 1.0149e-07, 3.1949e-06, 1.0511e-06,\n",
      "        3.3933e-08, 7.6788e-08, 1.2638e-07, 1.3089e-07, 1.1614e-07, 1.3423e-07,\n",
      "        1.4073e-05, 1.0113e-06, 2.6302e-07, 9.0801e-08, 3.2778e-07, 1.1878e-07,\n",
      "        5.7161e-08, 1.2477e-07, 2.2673e-08, 1.0173e-06, 2.6444e-08, 6.4824e-08,\n",
      "        2.7553e-08, 1.3214e-07, 1.5600e-08, 3.7464e-08, 1.2314e-08, 4.5085e-07,\n",
      "        3.1528e-08, 2.0388e-08, 2.3399e-08, 4.9175e-09, 4.9946e-08, 1.1187e-07,\n",
      "        8.6429e-08, 1.2438e-06, 5.5057e-07, 9.9446e-09, 5.4809e-08, 4.1631e-08,\n",
      "        2.2916e-08, 4.2464e-08, 9.1414e-08, 3.3688e-08, 2.2329e-07, 3.2814e-08,\n",
      "        2.0556e-06, 2.8301e-07, 1.7534e-07, 5.6492e-08, 6.4368e-08, 6.9794e-08,\n",
      "        1.0078e-07, 1.5868e-08, 9.8176e-07, 5.8514e-07, 1.0312e-06, 3.2841e-08,\n",
      "        1.2141e-08, 7.0014e-08, 1.3588e-08, 1.8086e-08, 2.9540e-08, 4.8089e-09,\n",
      "        3.4946e-07, 5.6062e-08, 1.8472e-06, 1.2335e-07, 1.7896e-06, 1.9219e-06,\n",
      "        2.8175e-07, 2.8311e-08, 3.4499e-07, 5.3780e-06, 1.4432e-07, 2.3682e-06,\n",
      "        5.2962e-07, 1.0378e-06, 1.7861e-06, 1.6900e-07, 2.7544e-07, 5.7284e-08,\n",
      "        1.2796e-07, 8.7023e-08, 1.8645e-07, 1.0942e-07, 2.0033e-07, 4.6735e-08,\n",
      "        3.0547e-07, 2.6252e-08, 1.7089e-08, 3.8680e-09, 6.8110e-09, 8.6527e-08,\n",
      "        2.0459e-08, 4.0831e-09, 5.3889e-08, 4.0219e-06], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "input_image=Image.open(filename)\n",
    "preprocess=T.Compose([\n",
    "    T.Resize((256,256)),T.CenterCrop(224),T.ToTensor(),T.Normalize((0.5,0.5,0.5),(1,1,1))\n",
    "])\n",
    "\n",
    "input_tensor=preprocess(input_image)\n",
    "input_batch=input_tensor.unsqueeze(0).to(device=torch.device(\"mps\"))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output=model(input_batch)\n",
    "\n",
    "probabs=torch.nn.functional.softmax(output[0],dim=0)\n",
    "print(probabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samoyed 0.923850417137146\n",
      "Pomeranian 0.04575949162244797\n",
      "keeshond 0.007945380173623562\n",
      "Persian cat 0.0065824235789477825\n",
      "Angora 0.0033248523250222206\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"imagenet_classes.txt\",\"r\") as f:\n",
    "    categories=[s.strip() for s in f.readlines()]\n",
    "\n",
    "top5_probab,top5_catid=torch.topk(probabs,5)\n",
    "\n",
    "for i in range(top5_probab.size(0)):\n",
    "     print(categories[top5_catid[i]], top5_probab[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
