{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZVV0TlImoSc",
        "outputId": "fba182ba-0eec-4a20-a79e-c9ea8a1e7f46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /Users/smudge/.cache/torch/hub/v0.10.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /Users/smudge/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n",
            "100%|██████████| 49.7M/49.7M [00:48<00:00, 1.07MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GoogLeNet(\n",
              "  (conv1): BasicConv2d(\n",
              "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (conv2): BasicConv2d(\n",
              "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (conv3): BasicConv2d(\n",
              "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception3a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception3b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception4a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4c): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4d): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4e): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception5a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception5b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (aux1): None\n",
              "  (aux2): None\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NhkaA-wvnJrq"
      },
      "outputs": [],
      "source": [
        "# Download an example image from the pytorch website\n",
        "import urllib\n",
        "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "try: urllib.URLopener().retrieve(url, filename)\n",
        "except: urllib.request.urlretrieve(url, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1t04DlPnLKj",
        "outputId": "f7f6b634-8424-44bc-d423-0b2d7f25dfe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 3.5609e-02, -2.2878e-01, -3.2326e-01,  5.5472e-02,  1.1363e-01,\n",
            "        -2.8251e-01,  6.1544e-01,  6.0953e-02,  9.4566e-01, -1.4981e+00,\n",
            "        -5.5102e-01, -3.6588e-02, -1.2635e+00, -3.1756e-02,  5.3338e-01,\n",
            "         1.8750e-01,  4.9309e-01, -2.8286e-01, -2.7196e-01, -2.6181e-01,\n",
            "        -3.3155e-01, -7.5720e-02,  6.7104e-02, -5.7091e-01, -5.3176e-01,\n",
            "        -4.9965e-02,  7.2163e-01,  1.1626e+00,  5.1519e-01,  1.3022e+00,\n",
            "         6.9073e-01,  5.5678e-01,  1.3273e-01, -7.1238e-01, -5.0567e-01,\n",
            "        -2.4467e-01, -5.9905e-01,  1.9404e-01, -3.2087e-01,  6.1736e-01,\n",
            "         2.9624e-01, -2.4294e-01,  1.8518e-01, -4.5889e-01,  1.5296e-01,\n",
            "        -6.8361e-01,  9.9018e-01,  6.1654e-01, -1.2935e+00, -4.6649e-01,\n",
            "        -7.1416e-02, -3.3975e-04,  3.7411e-01,  1.8117e-01,  8.5821e-01,\n",
            "         1.0058e+00, -3.0185e-01,  1.9627e-02,  7.9075e-02,  8.1202e-01,\n",
            "         7.7451e-01, -7.0558e-01, -2.2717e-01, -2.5872e-01,  1.5508e-01,\n",
            "        -4.5723e-01,  7.8180e-01,  1.4157e-01,  1.0196e+00, -6.3791e-01,\n",
            "         3.6661e-01, -8.5776e-01,  9.0045e-01,  2.4733e-01,  5.8530e-01,\n",
            "         7.4312e-02,  2.2643e-02, -1.4073e-01,  1.2126e+00,  2.1965e-01,\n",
            "        -4.7912e-01,  2.8475e-02,  5.7822e-01, -7.9263e-01,  2.0452e-01,\n",
            "        -1.3435e+00, -5.2833e-01, -9.1494e-01, -1.0384e+00,  1.2081e+00,\n",
            "         6.7540e-01, -9.7714e-01, -6.2081e-01, -8.3744e-01, -7.9462e-01,\n",
            "        -9.7247e-02, -4.7870e-01, -6.4316e-01, -8.9179e-01,  1.4201e-01,\n",
            "         1.5334e+00, -3.6900e-01,  3.9428e-02, -1.0652e+00,  2.1422e+00,\n",
            "         1.0718e-02,  4.7727e-01, -1.3408e+00, -1.7166e-01, -7.6164e-01,\n",
            "        -8.7229e-03, -1.4409e+00,  7.5086e-01,  1.0382e-01,  9.9494e-01,\n",
            "         7.9119e-01, -5.2683e-01, -1.0767e+00,  1.5027e-01,  1.2637e+00,\n",
            "        -9.0515e-01, -3.5881e-01,  5.3269e-01,  2.3710e-01,  4.7109e-01,\n",
            "         4.2450e-01, -3.2671e-01,  3.7609e-01, -7.7519e-01,  4.1264e-01,\n",
            "        -1.2280e+00, -3.1647e-01,  1.2660e+00, -1.8617e+00, -3.4123e-02,\n",
            "        -2.5280e-01, -1.2166e+00, -1.2271e+00, -1.3598e+00, -6.5224e-01,\n",
            "        -1.0908e+00, -9.2660e-01, -8.1402e-01,  2.3241e-01,  1.2066e-01,\n",
            "        -7.3433e-01,  1.0776e+00, -9.5819e-01, -1.3134e+00, -3.3126e-01,\n",
            "        -1.7442e+00,  8.8546e-01,  2.7585e+00,  2.1534e+00,  2.6076e+00,\n",
            "        -8.4845e-02,  7.0084e-02,  3.2225e+00, -8.2181e-01, -1.1045e+00,\n",
            "        -1.1007e+00, -1.8172e+00, -1.6127e+00, -3.0122e+00, -1.7534e+00,\n",
            "        -1.3869e+00, -1.3422e+00, -2.2503e+00, -1.4988e+00,  8.0288e-01,\n",
            "         2.2173e-01, -1.6786e+00, -1.8998e+00, -4.9848e-01,  1.6308e+00,\n",
            "        -1.1981e+00, -1.6312e+00, -1.1828e+00, -1.5884e+00, -7.8499e-01,\n",
            "        -2.9097e-01, -1.6389e+00, -2.0777e+00, -1.9918e+00, -1.3888e+00,\n",
            "         3.6734e-01,  1.5592e+00, -1.4144e+00, -1.9432e-01, -2.2735e+00,\n",
            "        -1.1239e-01, -2.1212e+00,  1.6591e+00,  5.0070e-01, -8.8058e-01,\n",
            "        -1.0840e+00, -1.9342e+00, -5.3891e-01, -1.4462e+00,  7.3370e-01,\n",
            "         4.4591e-01, -7.7604e-01, -1.5428e+00,  4.7521e+00, -3.7515e-01,\n",
            "        -4.3327e-01, -1.8382e+00,  2.3102e+00,  6.9238e-02, -1.7762e+00,\n",
            "        -2.4657e+00, -1.7878e+00,  2.7571e-01, -1.2037e+00, -7.4176e-01,\n",
            "        -9.9294e-03,  6.5810e-01, -2.2502e-01, -3.4668e-01, -1.4092e+00,\n",
            "        -1.5803e+00, -1.6941e+00,  4.3832e+00,  2.5385e+00,  3.3776e+00,\n",
            "        -1.0301e+00,  9.6490e-01,  8.6441e-02,  9.3403e-01,  2.4959e+00,\n",
            "         3.6288e+00,  3.7899e+00,  3.8152e+00,  2.9074e-01, -2.4349e-01,\n",
            "         8.9794e-01, -2.6600e-01, -1.4105e+00, -6.5378e-01,  8.5767e-01,\n",
            "         6.0564e-01,  6.0313e-01, -1.2349e+00, -1.7813e+00,  1.7006e-01,\n",
            "        -1.5635e+00, -2.5254e+00,  1.0813e+00,  4.7321e+00,  4.2914e+00,\n",
            "         3.9064e+00,  3.9779e-01, -6.3440e-01, -7.8779e-01, -1.0389e+00,\n",
            "        -6.5346e-01,  1.6996e+00,  5.7113e+00,  1.0832e+01,  6.1022e+00,\n",
            "         4.3070e+00,  4.4199e+00, -1.3711e+00,  1.3481e+00,  4.5476e-01,\n",
            "         4.4129e-02, -5.8699e-02,  4.8729e-01, -2.3789e+00,  2.2411e+00,\n",
            "         5.5442e+00, -2.9314e-01, -5.4829e-01,  8.8465e-02,  7.7425e-01,\n",
            "        -2.2289e+00, -1.1821e+00,  5.1806e-01,  1.6656e-02,  5.6978e+00,\n",
            "         3.9968e-01,  6.9130e-01,  5.8708e-01,  3.9757e+00,  1.1034e+00,\n",
            "         2.1488e-01, -9.1533e-01,  1.3669e+00, -4.2841e-01, -2.1551e-01,\n",
            "         2.6102e-02, -6.1778e-01, -6.4613e-02, -6.4967e-01, -2.8096e-01,\n",
            "        -2.0293e-01,  1.2006e+00,  3.4749e-01, -9.2912e-01, -2.7310e-01,\n",
            "         8.4898e-01,  5.0256e-01,  8.5425e-02, -1.8680e-01,  9.1463e-01,\n",
            "        -5.2516e-01,  6.1481e-01, -2.9869e-02, -6.0983e-01, -3.8733e-01,\n",
            "         1.0033e+00,  9.7573e-01,  8.3908e-01,  1.2844e+00,  9.9897e-01,\n",
            "         1.6349e-01,  5.9431e-01,  7.3282e-01,  6.5502e-01,  7.9399e-01,\n",
            "         8.6042e-01,  4.7070e-01, -1.4550e-01,  2.6090e-01,  4.0873e-01,\n",
            "         5.2005e-01,  7.5405e-01,  6.5671e-01, -2.1129e-01,  7.3908e-01,\n",
            "        -1.3712e+00, -1.8747e-01,  2.8425e+00,  1.7757e+00, -1.2110e-01,\n",
            "         5.9488e-01,  2.4049e-01, -4.9349e-01,  9.3597e-01,  1.1249e-01,\n",
            "         1.2116e-01,  9.6991e-02, -1.0692e+00, -1.7705e+00, -1.6674e+00,\n",
            "        -6.4421e-01, -8.1190e-01, -6.0554e-01, -3.2002e-01, -2.1044e+00,\n",
            "        -1.5605e+00, -1.2767e+00, -2.1196e+00, -8.7402e-01, -1.5694e+00,\n",
            "         7.5372e-01,  8.2036e-01, -1.5219e-01,  1.1140e+00,  6.4987e-01,\n",
            "        -1.6276e+00,  1.0295e+00, -6.5943e-01,  1.8632e-01, -1.1066e+00,\n",
            "        -1.4453e+00, -1.1959e+00, -1.4228e+00,  4.1849e-01, -8.1253e-01,\n",
            "        -6.2538e-01, -7.0935e-01, -7.7660e-01,  4.9920e-01,  4.7309e-01,\n",
            "        -1.0971e+00, -1.9222e+00,  9.2840e-01, -1.0064e+00, -1.1537e+00,\n",
            "        -1.0046e-01, -4.6650e-01,  1.4137e-01,  3.6613e-01,  2.3097e-01,\n",
            "        -6.6480e-01, -1.6682e+00,  1.4604e+00,  1.7634e+00, -3.2488e-01,\n",
            "        -3.2992e-01, -2.7372e-01, -1.2326e+00, -1.0564e+00, -5.2048e-01,\n",
            "         3.5363e-01, -1.3362e-01, -1.0854e+00,  5.1892e-01, -6.4103e-01,\n",
            "        -1.0232e+00,  8.0298e-02, -4.9111e-01, -7.3774e-01, -2.1530e-01,\n",
            "        -2.4924e-01, -6.5395e-01, -4.8027e-01, -8.0138e-01,  5.0244e-01,\n",
            "         2.4394e-01, -5.9734e-01,  9.0451e-01, -7.0233e-01,  3.1060e-02,\n",
            "         3.2453e-01, -1.6000e-01, -1.9891e-01, -1.7467e-02,  9.6658e-01,\n",
            "        -3.5370e-01, -1.7970e-01, -1.3314e+00, -3.0983e-01, -1.0982e-01,\n",
            "         1.0997e+00, -1.7973e-01,  2.8900e-01, -1.5429e-01,  4.0364e-01,\n",
            "        -1.1512e+00, -7.3060e-01, -2.6429e-01, -4.5204e-01, -1.0702e+00,\n",
            "         9.9457e-01, -4.5294e-01,  6.5208e-02, -5.2285e-01,  5.2612e-01,\n",
            "         3.0513e-01, -1.6928e-02, -4.3593e-01, -1.1345e-01, -2.6571e-01,\n",
            "         5.4630e-01, -3.1390e-01,  2.6089e-01, -2.4049e-01,  6.2626e-01,\n",
            "        -7.8179e-01, -5.5212e-01, -3.7289e-01,  7.6495e-01,  7.7482e-01,\n",
            "         1.1986e+00, -2.7995e-01, -5.3765e-01,  4.2925e-01, -4.3981e-01,\n",
            "         2.5314e-01, -6.6337e-01,  3.8728e-01,  1.0268e+00, -6.3746e-01,\n",
            "        -2.1882e-01,  6.3782e-02, -6.5960e-01, -5.2809e-01, -9.5180e-01,\n",
            "         3.1120e-01,  5.0105e-01,  6.0200e-01,  6.5831e-01, -5.4279e-01,\n",
            "        -6.6137e-01, -4.5533e-01, -9.3520e-01,  8.8670e-01,  8.5934e-01,\n",
            "        -2.8237e-01, -8.0239e-01, -1.3113e+00,  1.6156e+00,  2.8014e-01,\n",
            "        -1.5627e+00, -3.6159e-01, -7.9473e-01, -3.5516e-01,  1.0328e+00,\n",
            "        -1.1025e+00, -1.0733e+00, -8.6102e-03,  1.0256e-01, -6.0817e-02,\n",
            "         2.2718e-01,  5.7245e-01,  5.3970e-01, -1.0795e+00, -9.2669e-01,\n",
            "        -1.3420e+00, -5.3595e-01,  7.7341e-01, -8.4763e-01, -2.2252e-01,\n",
            "        -5.1444e-01,  6.6314e-02, -8.6818e-02,  2.1138e-01,  8.4519e-01,\n",
            "         3.6555e-01, -6.9170e-01,  2.7502e-02, -5.6335e-01, -3.3489e-01,\n",
            "         1.0908e-01, -5.5583e-01, -6.0106e-01, -1.2104e+00,  5.3710e-01,\n",
            "        -4.8787e-01, -4.1172e-01,  1.2224e+00, -6.9935e-01,  2.4063e-01,\n",
            "         1.0367e-01, -1.4934e-01, -6.7729e-01, -7.9333e-01,  4.5296e-01,\n",
            "        -2.8288e-01,  1.8976e-01, -5.2173e-01, -4.8378e-01,  5.9682e-01,\n",
            "        -5.4344e-01,  1.5581e-01, -4.7816e-02, -5.8863e-01,  2.6965e+00,\n",
            "        -1.3583e+00,  6.0399e-01,  6.7672e-01, -3.3019e-01, -8.1895e-01,\n",
            "        -1.2348e-02, -7.4799e-01, -6.8553e-01, -2.8918e-01,  3.5147e-01,\n",
            "        -3.9225e-01,  3.2456e-01,  6.1159e-02,  1.5760e-01, -1.3476e+00,\n",
            "        -1.0204e+00, -6.3235e-01,  7.5632e-01, -2.5589e-01,  5.0208e-01,\n",
            "        -4.8046e-01, -6.9826e-01, -6.8039e-01, -2.5828e-01, -3.6736e-01,\n",
            "        -7.9490e-01,  9.3736e-01, -2.1486e-01, -2.8257e-01,  7.7238e-01,\n",
            "        -5.3273e-01, -9.5074e-01, -5.3553e-01, -1.0028e+00,  6.0457e-01,\n",
            "        -3.5174e-01, -8.0575e-01,  4.1427e-01,  4.3586e-01, -2.8346e-01,\n",
            "         1.0784e+00, -3.7876e-01,  3.9135e-01, -7.0574e-01, -2.7474e-01,\n",
            "        -2.4859e-01, -3.5297e-01, -1.9707e-01,  4.2273e-01, -9.0614e-01,\n",
            "        -1.0496e+00, -5.5391e-01, -9.9667e-01, -8.6367e-02, -3.7651e-01,\n",
            "         4.5491e-01,  9.6107e-01, -6.7478e-01, -2.6355e-01,  1.2127e-01,\n",
            "        -7.7206e-01, -5.4978e-02, -3.8312e-01, -5.5122e-01,  1.7524e-02,\n",
            "        -9.1819e-01, -3.3785e-01, -3.7212e-01, -5.1973e-01, -7.5171e-01,\n",
            "        -7.0565e-01,  6.6643e-01, -2.2380e-01, -1.2061e+00,  8.8042e-01,\n",
            "        -7.6270e-01, -1.8595e+00, -4.4348e-01, -7.3224e-01, -7.5110e-01,\n",
            "        -1.7356e-01,  1.1147e+00,  8.5556e-01,  2.7333e-01,  6.6173e-01,\n",
            "        -1.4254e-01, -2.8623e-01,  1.5045e-01,  6.6115e-01,  5.8569e-01,\n",
            "         7.6401e-01,  1.3555e+00, -2.2469e-01,  9.4323e-01, -1.1214e+00,\n",
            "         3.0405e-01,  8.5708e-01,  7.0383e-01, -5.5830e-02, -2.8462e-01,\n",
            "         6.4083e-01,  4.3884e-01, -4.5954e-01, -1.9189e-01, -3.8082e-02,\n",
            "        -3.0575e-01,  1.0839e+00, -2.4280e-01,  1.2532e-01,  4.8656e-01,\n",
            "        -1.1438e+00, -8.1460e-01,  1.1256e-02,  8.1423e-01, -6.5076e-01,\n",
            "        -3.1386e-02, -2.2221e-01, -2.3743e-01,  4.9488e-01,  1.5618e-01,\n",
            "         4.1529e-01,  2.1668e-02, -1.5078e+00, -1.2993e-01, -5.1985e-02,\n",
            "         1.5928e-01, -2.0889e-01, -7.4737e-01, -8.7439e-01, -5.9282e-01,\n",
            "         5.9350e-01, -2.7755e-01, -1.9452e-01, -5.6798e-01,  2.7460e-01,\n",
            "        -9.3735e-01,  2.1678e-01,  6.7748e-01, -1.0684e+00, -7.9270e-01,\n",
            "        -4.7843e-01, -1.0534e-01, -8.1416e-01, -9.2718e-01, -8.5372e-02,\n",
            "        -3.0925e-01, -5.9519e-01, -6.9855e-01, -7.4407e-01, -5.8933e-01,\n",
            "        -1.3991e+00, -1.5812e+00,  7.7109e-01, -8.1183e-01, -1.0567e-01,\n",
            "         1.4833e-01,  5.4306e-01, -1.8159e-01,  6.5966e-01, -4.4553e-01,\n",
            "         4.0423e-01, -3.3142e-01, -1.0266e+00,  1.3925e+00, -5.2535e-01,\n",
            "        -8.8450e-01,  8.1033e-01, -8.6215e-01, -5.1140e-02, -8.9545e-01,\n",
            "         1.4049e-01,  8.2731e-01, -8.1304e-02, -3.0760e-01, -1.5938e-02,\n",
            "        -1.4235e+00,  1.4255e+00, -8.3399e-01, -5.6609e-01,  7.8957e-01,\n",
            "         1.1771e-01,  1.1989e-01,  6.4467e-01,  1.3605e+00,  5.7759e-01,\n",
            "        -9.5906e-02, -1.6846e+00,  1.7498e-01,  1.1560e+00, -7.3278e-01,\n",
            "         4.0854e-01,  1.6851e-01, -3.8409e-01,  6.6483e-02, -4.4498e-02,\n",
            "        -3.2634e-01, -7.3040e-01, -3.6166e-02,  3.3436e-01, -1.3387e+00,\n",
            "        -9.0693e-01, -1.1936e-03,  2.9446e-01,  4.3069e-01, -6.8166e-01,\n",
            "        -4.7167e-01, -2.0933e-01, -7.8857e-01,  2.6597e-01,  6.4026e-01,\n",
            "         5.3799e-01, -3.6295e-01, -7.8553e-02,  1.0843e+00, -1.0598e+00,\n",
            "         6.4515e-01,  7.6392e-01, -5.6476e-01,  1.4119e-01,  5.3239e-01,\n",
            "         7.0649e-01,  3.1941e-01, -4.5225e-02,  2.9411e-01, -1.3734e-01,\n",
            "         2.8452e-01,  6.6552e-02, -9.9088e-02,  4.7028e-01, -7.5839e-02,\n",
            "         1.4189e-01, -6.5463e-02,  3.1011e-01, -1.0710e-01,  6.8495e-01,\n",
            "        -4.2109e-01, -3.7335e-01, -1.0715e-01, -2.1595e-01, -2.2912e-01,\n",
            "         1.3451e-01, -4.0129e-01,  1.5042e-01,  7.8970e-01, -5.2447e-01,\n",
            "        -1.4643e+00,  1.2258e-01, -6.1349e-01,  1.2903e+00,  7.4365e-01,\n",
            "        -7.8442e-01, -3.7276e-01,  4.1457e-01, -6.8892e-01, -2.1468e-01,\n",
            "        -1.0444e+00, -1.2021e+00, -4.6716e-01, -8.9998e-01,  8.5642e-01,\n",
            "         7.8104e-02, -1.1772e+00, -1.1222e+00, -1.3061e+00,  4.8075e-01,\n",
            "         1.3086e+00,  6.7640e-01,  1.8485e-01, -1.0501e+00, -1.3882e+00,\n",
            "         2.3545e-01,  9.0298e-01, -1.8194e+00,  2.3997e-01, -8.7802e-03,\n",
            "         1.5278e+00, -3.4627e-01, -4.3690e-01,  2.3462e-01, -1.1197e+00,\n",
            "         1.2962e-01, -5.4479e-01, -2.2730e-01,  2.1025e-01,  3.9196e-02,\n",
            "         7.9660e-01,  5.7952e-01, -5.9427e-01,  4.0452e-01, -2.9030e-01,\n",
            "        -1.5066e+00,  2.0624e-01, -4.5646e-01, -7.4837e-01, -6.1526e-01,\n",
            "        -1.7147e-01, -1.1778e-01, -1.2484e-01,  1.1982e+00, -5.4845e-01,\n",
            "        -1.0519e+00, -4.0591e-01, -3.5259e-01,  5.1157e-01, -3.1235e-01,\n",
            "         3.8747e-01, -1.0345e+00, -1.9627e-01, -8.8467e-01, -3.2810e-01,\n",
            "         2.5163e-01, -7.2509e-01,  1.4092e+00,  9.5119e-01, -3.6204e-01,\n",
            "         2.6323e-01, -9.1472e-01, -7.4253e-01,  1.1217e+00, -6.7554e-01,\n",
            "         6.5347e-01,  6.7347e-01, -8.5280e-01, -4.5023e-01, -7.7801e-01,\n",
            "         7.1293e-02,  5.0682e-01, -4.9282e-01,  2.0157e-01,  1.9136e-01,\n",
            "         1.0317e+00,  7.6620e-03,  5.5711e-02, -9.7061e-01, -4.0203e-01,\n",
            "        -5.0581e-01,  1.1539e+00,  1.5273e-02,  1.6420e-01,  6.4376e-01,\n",
            "        -3.7314e-01, -1.4422e-01,  3.4270e-02, -3.9388e-01, -1.0385e-01,\n",
            "         1.9563e-01,  4.2462e-01, -9.9843e-01,  2.1070e-01, -9.3378e-01,\n",
            "        -1.0217e+00, -5.6076e-01,  5.4740e-01,  6.5389e-02, -5.2482e-01,\n",
            "        -7.7891e-01,  3.0673e-01,  6.1032e-01, -3.8202e-01,  4.9421e-02,\n",
            "        -1.7575e-01, -5.3460e-01,  8.7635e-01, -3.7151e-01,  1.4366e+00,\n",
            "         9.8706e-01, -7.8224e-01, -1.8592e-01, -6.3144e-03, -7.9297e-01,\n",
            "        -3.9622e-01, -1.4567e-01,  1.3112e+00,  1.9927e-01, -7.9441e-01,\n",
            "        -1.0502e+00,  5.2885e-01, -1.0967e+00,  2.0053e-01, -4.3015e-01,\n",
            "         2.6913e-01, -3.8994e-01,  1.8427e-01, -2.8351e-01, -6.0650e-03,\n",
            "         1.1469e-01, -2.9935e-01, -1.9675e-01, -9.3912e-01,  1.5047e+00,\n",
            "         1.3258e-01, -6.5813e-01,  8.4526e-02, -5.6557e-01, -9.1811e-01,\n",
            "        -1.0176e-01,  3.9915e-01,  5.7630e-01,  8.5934e-01,  4.5999e-01,\n",
            "        -8.8732e-01, -9.2226e-01, -4.1232e-01,  8.6883e-01,  2.2862e-01,\n",
            "        -2.0206e-02,  1.1186e+00,  5.0987e-01,  1.0104e+00,  1.2311e+00,\n",
            "        -6.9669e-02,  7.2052e-01, -4.8941e-01,  7.1993e-01, -5.8729e-01,\n",
            "         2.1873e-02,  7.9356e-01,  1.0294e+00,  6.9855e-01, -1.1138e+00,\n",
            "        -1.4502e+00,  6.0494e-01, -5.1734e-01, -2.4062e-01, -4.6572e-01,\n",
            "        -1.1137e+00, -7.3146e-01,  2.8379e-02, -3.7967e-02,  1.7428e-01,\n",
            "         7.7703e-01, -1.4989e-01, -7.5455e-02, -3.8519e-01,  4.7851e-01,\n",
            "         1.3231e+00,  4.8374e-01,  6.9333e-01,  3.0281e-01,  4.4286e-01,\n",
            "         2.3477e-01, -1.7129e-01,  6.4133e-01, -1.1592e-02,  1.2955e+00,\n",
            "         3.3206e-01,  9.0901e-01, -5.5993e-02,  1.9368e-01,  9.3904e-01,\n",
            "         1.7239e+00,  2.4749e-01,  8.6547e-01, -1.0735e+00, -3.2029e-01,\n",
            "         1.0495e-01, -4.5603e-01, -4.7345e-01,  2.9702e-01,  2.9929e-01])\n",
            "tensor([1.9209e-05, 1.4746e-05, 1.3417e-05, 1.9595e-05, 2.0768e-05, 1.3975e-05,\n",
            "        3.4303e-05, 1.9702e-05, 4.7724e-05, 4.1441e-06, 1.0684e-05, 1.7871e-05,\n",
            "        5.2396e-06, 1.7958e-05, 3.1600e-05, 2.2360e-05, 3.0352e-05, 1.3970e-05,\n",
            "        1.4123e-05, 1.4267e-05, 1.3306e-05, 1.7185e-05, 1.9824e-05, 1.0474e-05,\n",
            "        1.0892e-05, 1.7634e-05, 3.8146e-05, 5.9286e-05, 3.1031e-05, 6.8169e-05,\n",
            "        3.6985e-05, 3.2348e-05, 2.1169e-05, 9.0921e-06, 1.1180e-05, 1.4514e-05,\n",
            "        1.0183e-05, 2.2507e-05, 1.3449e-05, 3.4368e-05, 2.4929e-05, 1.4539e-05,\n",
            "        2.2308e-05, 1.1715e-05, 2.1601e-05, 9.3574e-06, 4.9897e-05, 3.4340e-05,\n",
            "        5.0850e-06, 1.1626e-05, 1.7260e-05, 1.8531e-05, 2.6947e-05, 2.2219e-05,\n",
            "        4.3728e-05, 5.0684e-05, 1.3707e-05, 1.8905e-05, 2.0063e-05, 4.1754e-05,\n",
            "        4.0217e-05, 9.1541e-06, 1.4770e-05, 1.4312e-05, 2.1647e-05, 1.1735e-05,\n",
            "        4.0511e-05, 2.1356e-05, 5.1385e-05, 9.7950e-06, 2.6746e-05, 7.8618e-06,\n",
            "        4.5615e-05, 2.3739e-05, 3.3284e-05, 1.9967e-05, 1.8962e-05, 1.6104e-05,\n",
            "        6.2325e-05, 2.3091e-05, 1.1481e-05, 1.9073e-05, 3.3049e-05, 8.3909e-06,\n",
            "        2.2744e-05, 4.8370e-06, 1.0929e-05, 7.4249e-06, 6.5625e-06, 6.2049e-05,\n",
            "        3.6422e-05, 6.9771e-06, 9.9640e-06, 8.0232e-06, 8.3742e-06, 1.6819e-05,\n",
            "        1.1485e-05, 9.7437e-06, 7.5988e-06, 2.1366e-05, 8.5903e-05, 1.2817e-05,\n",
            "        1.9283e-05, 6.3889e-06, 1.5791e-04, 1.8737e-05, 2.9876e-05, 4.8501e-06,\n",
            "        1.5613e-05, 8.6550e-06, 1.8376e-05, 4.3881e-06, 3.9277e-05, 2.0565e-05,\n",
            "        5.0135e-05, 4.0893e-05, 1.0946e-05, 6.3161e-06, 2.1543e-05, 6.5591e-05,\n",
            "        7.4980e-06, 1.2948e-05, 3.1578e-05, 2.3497e-05, 2.9692e-05, 2.8340e-05,\n",
            "        1.3371e-05, 2.7001e-05, 8.5386e-06, 2.8006e-05, 5.4291e-06, 1.3508e-05,\n",
            "        6.5743e-05, 2.8810e-06, 1.7915e-05, 1.4396e-05, 5.4913e-06, 5.4341e-06,\n",
            "        4.7589e-06, 9.6556e-06, 6.2277e-06, 7.3388e-06, 8.2134e-06, 2.3387e-05,\n",
            "        2.0914e-05, 8.8946e-06, 5.4455e-05, 7.1106e-06, 4.9845e-06, 1.3310e-05,\n",
            "        3.2399e-06, 4.4936e-05, 2.9244e-04, 1.5968e-04, 2.5149e-04, 1.7029e-05,\n",
            "        1.9883e-05, 4.6511e-04, 8.1496e-06, 6.1428e-06, 6.1662e-06, 3.0120e-06,\n",
            "        3.6953e-06, 9.1174e-07, 3.2105e-06, 4.6316e-06, 4.8430e-06, 1.9533e-06,\n",
            "        4.1410e-06, 4.1374e-05, 2.3139e-05, 3.4598e-06, 2.7732e-06, 1.1260e-05,\n",
            "        9.4687e-05, 5.5938e-06, 3.6278e-06, 5.6803e-06, 3.7862e-06, 8.4553e-06,\n",
            "        1.3857e-05, 3.5998e-06, 2.3213e-06, 2.5295e-06, 4.6227e-06, 2.6766e-05,\n",
            "        8.8147e-05, 4.5057e-06, 1.5263e-05, 1.9085e-06, 1.6567e-05, 2.2224e-06,\n",
            "        9.7402e-05, 3.0584e-05, 7.6845e-06, 6.2702e-06, 2.6793e-06, 1.0814e-05,\n",
            "        4.3649e-06, 3.8609e-05, 2.8953e-05, 8.5313e-06, 3.9631e-06, 2.1471e-03,\n",
            "        1.2739e-05, 1.2019e-05, 2.9493e-06, 1.8680e-04, 1.9866e-05, 3.1381e-06,\n",
            "        1.5748e-06, 3.1018e-06, 2.4422e-05, 5.5625e-06, 8.8288e-06, 1.8354e-05,\n",
            "        3.5798e-05, 1.4802e-05, 1.3106e-05, 4.5295e-06, 3.8171e-06, 3.4063e-06,\n",
            "        1.4847e-03, 2.3469e-04, 5.4312e-04, 6.6175e-06, 4.8651e-05, 2.0211e-05,\n",
            "        4.7173e-05, 2.2491e-04, 6.9825e-04, 8.2028e-04, 8.4133e-04, 2.4792e-05,\n",
            "        1.4531e-05, 4.5501e-05, 1.4208e-05, 4.5236e-06, 9.6408e-06, 4.3704e-05,\n",
            "        3.3968e-05, 3.3883e-05, 5.3919e-06, 3.1219e-06, 2.1974e-05, 3.8817e-06,\n",
            "        1.4835e-06, 5.4655e-05, 2.1045e-03, 1.3545e-03, 9.2167e-04, 2.7593e-05,\n",
            "        9.8295e-06, 8.4316e-06, 6.5596e-06, 9.6439e-06, 1.0143e-04, 5.6031e-03,\n",
            "        9.3784e-01, 8.2835e-03, 1.3758e-03, 1.5402e-03, 4.7053e-06, 7.1368e-05,\n",
            "        2.9211e-05, 1.9374e-05, 1.7480e-05, 3.0177e-05, 1.7175e-06, 1.7432e-04,\n",
            "        4.7410e-03, 1.3827e-05, 1.0713e-05, 2.0252e-05, 4.0207e-05, 1.9955e-06,\n",
            "        5.6841e-06, 3.1120e-05, 1.8849e-05, 5.5278e-03, 2.7646e-05, 3.7006e-05,\n",
            "        3.3343e-05, 9.8778e-04, 5.5879e-05, 2.2981e-05, 7.4220e-06, 7.2723e-05,\n",
            "        1.2078e-05, 1.4943e-05, 1.9027e-05, 9.9941e-06, 1.7377e-05, 9.6805e-06,\n",
            "        1.3997e-05, 1.5133e-05, 6.1583e-05, 2.6240e-05, 7.3204e-06, 1.4107e-05,\n",
            "        4.3326e-05, 3.0641e-05, 2.0190e-05, 1.5379e-05, 4.6266e-05, 1.0964e-05,\n",
            "        3.4281e-05, 1.7992e-05, 1.0074e-05, 1.2584e-05, 5.0556e-05, 4.9181e-05,\n",
            "        4.2900e-05, 6.6968e-05, 5.0338e-05, 2.1830e-05, 3.3586e-05, 3.8575e-05,\n",
            "        3.5687e-05, 4.1008e-05, 4.3825e-05, 2.9680e-05, 1.6027e-05, 2.4063e-05,\n",
            "        2.7897e-05, 3.1182e-05, 3.9402e-05, 3.5748e-05, 1.5007e-05, 3.8817e-05,\n",
            "        4.7047e-06, 1.5368e-05, 3.1808e-04, 1.0945e-04, 1.6423e-05, 3.3604e-05,\n",
            "        2.3577e-05, 1.1317e-05, 4.7264e-05, 2.0744e-05, 2.0925e-05, 2.0425e-05,\n",
            "        6.3633e-06, 3.1560e-06, 3.4986e-06, 9.7334e-06, 8.2308e-06, 1.0117e-05,\n",
            "        1.3460e-05, 2.2601e-06, 3.8936e-06, 5.1709e-06, 2.2259e-06, 7.7350e-06,\n",
            "        3.8591e-06, 3.9389e-05, 4.2104e-05, 1.5920e-05, 5.6471e-05, 3.5504e-05,\n",
            "        3.6407e-06, 5.1897e-05, 9.5865e-06, 2.2334e-05, 6.1296e-06, 4.3688e-06,\n",
            "        5.6062e-06, 4.4683e-06, 2.8170e-05, 8.2256e-06, 9.9185e-06, 9.1197e-06,\n",
            "        8.5265e-06, 3.0538e-05, 2.9751e-05, 6.1887e-06, 2.7118e-06, 4.6907e-05,\n",
            "        6.7758e-06, 5.8481e-06, 1.6765e-05, 1.1626e-05, 2.1352e-05, 2.6733e-05,\n",
            "        2.3354e-05, 9.5351e-06, 3.4960e-06, 7.9849e-05, 1.0812e-04, 1.3395e-05,\n",
            "        1.3328e-05, 1.4098e-05, 5.4045e-06, 6.4458e-06, 1.1016e-05, 2.6401e-05,\n",
            "        1.6219e-05, 6.2611e-06, 3.1147e-05, 9.7645e-06, 6.6630e-06, 2.0087e-05,\n",
            "        1.1344e-05, 8.8644e-06, 1.4947e-05, 1.4448e-05, 9.6391e-06, 1.1467e-05,\n",
            "        8.3178e-06, 3.0637e-05, 2.3658e-05, 1.0201e-05, 4.5800e-05, 9.1839e-06,\n",
            "        1.9122e-05, 2.5644e-05, 1.5796e-05, 1.5194e-05, 1.8216e-05, 4.8733e-05,\n",
            "        1.3015e-05, 1.5488e-05, 4.8958e-06, 1.3598e-05, 1.6609e-05, 5.5674e-05,\n",
            "        1.5488e-05, 2.4749e-05, 1.5887e-05, 2.7755e-05, 5.8627e-06, 8.9279e-06,\n",
            "        1.4232e-05, 1.1796e-05, 6.3572e-06, 5.0116e-05, 1.1785e-05, 1.9786e-05,\n",
            "        1.0989e-05, 3.1372e-05, 2.5151e-05, 1.8226e-05, 1.1987e-05, 1.6549e-05,\n",
            "        1.4212e-05, 3.2011e-05, 1.3543e-05, 2.4063e-05, 1.4575e-05, 3.4676e-05,\n",
            "        8.4824e-06, 1.0672e-05, 1.2767e-05, 3.9834e-05, 4.0229e-05, 6.1458e-05,\n",
            "        1.4011e-05, 1.0828e-05, 2.8475e-05, 1.1941e-05, 2.3877e-05, 9.5488e-06,\n",
            "        2.7305e-05, 5.1759e-05, 9.7994e-06, 1.4894e-05, 1.9758e-05, 9.5848e-06,\n",
            "        1.0932e-05, 7.1562e-06, 2.5304e-05, 3.0595e-05, 3.3845e-05, 3.5805e-05,\n",
            "        1.0772e-05, 9.5678e-06, 1.1757e-05, 7.2760e-06, 4.4992e-05, 4.3778e-05,\n",
            "        1.3977e-05, 8.3094e-06, 4.9954e-06, 9.3260e-05, 2.4531e-05, 3.8849e-06,\n",
            "        1.2912e-05, 8.3734e-06, 1.2996e-05, 5.2068e-05, 6.1549e-06, 6.3373e-06,\n",
            "        1.8378e-05, 2.0539e-05, 1.7443e-05, 2.3265e-05, 3.2859e-05, 3.1800e-05,\n",
            "        6.2984e-06, 7.3382e-06, 4.8443e-06, 1.0846e-05, 4.0173e-05, 7.9419e-06,\n",
            "        1.4839e-05, 1.1082e-05, 1.9808e-05, 1.6996e-05, 2.2901e-05, 4.3162e-05,\n",
            "        2.6718e-05, 9.2820e-06, 1.9054e-05, 1.0553e-05, 1.3262e-05, 2.0674e-05,\n",
            "        1.0633e-05, 1.0163e-05, 5.5256e-06, 3.1718e-05, 1.1381e-05, 1.2281e-05,\n",
            "        6.2938e-05, 9.2113e-06, 2.3580e-05, 2.0562e-05, 1.5966e-05, 9.4167e-06,\n",
            "        8.3850e-06, 2.9158e-05, 1.3970e-05, 2.2411e-05, 1.1002e-05, 1.1427e-05,\n",
            "        3.3670e-05, 1.0765e-05, 2.1663e-05, 1.7672e-05, 1.0290e-05, 2.7485e-04,\n",
            "        4.7660e-06, 3.3912e-05, 3.6470e-05, 1.3324e-05, 8.1730e-06, 1.8310e-05,\n",
            "        8.7740e-06, 9.3395e-06, 1.3882e-05, 2.6344e-05, 1.2523e-05, 2.5645e-05,\n",
            "        1.9706e-05, 2.1702e-05, 4.8171e-06, 6.6820e-06, 9.8495e-06, 3.9492e-05,\n",
            "        1.4352e-05, 3.0626e-05, 1.1465e-05, 9.2213e-06, 9.3876e-06, 1.4318e-05,\n",
            "        1.2838e-05, 8.3719e-06, 4.7330e-05, 1.4953e-05, 1.3974e-05, 4.0132e-05,\n",
            "        1.0881e-05, 7.1638e-06, 1.0851e-05, 6.8004e-06, 3.3932e-05, 1.3040e-05,\n",
            "        8.2816e-06, 2.8052e-05, 2.8664e-05, 1.3962e-05, 5.4497e-05, 1.2693e-05,\n",
            "        2.7416e-05, 9.1526e-06, 1.4084e-05, 1.4457e-05, 1.3024e-05, 1.5222e-05,\n",
            "        2.8290e-05, 7.4905e-06, 6.4894e-06, 1.0653e-05, 6.8422e-06, 1.7003e-05,\n",
            "        1.2721e-05, 2.9215e-05, 4.8465e-05, 9.4405e-06, 1.4242e-05, 2.0927e-05,\n",
            "        8.5653e-06, 1.7546e-05, 1.2637e-05, 1.0682e-05, 1.8865e-05, 7.4008e-06,\n",
            "        1.3223e-05, 1.2777e-05, 1.1024e-05, 8.7414e-06, 9.1535e-06, 3.6097e-05,\n",
            "        1.4820e-05, 5.5494e-06, 4.4710e-05, 8.6458e-06, 2.8872e-06, 1.1897e-05,\n",
            "        8.9132e-06, 8.7467e-06, 1.5584e-05, 5.6514e-05, 4.3613e-05, 2.4364e-05,\n",
            "        3.5928e-05, 1.6075e-05, 1.3923e-05, 2.1547e-05, 3.5907e-05, 3.3297e-05,\n",
            "        3.9797e-05, 7.1903e-05, 1.4807e-05, 4.7608e-05, 6.0396e-06, 2.5124e-05,\n",
            "        4.3679e-05, 3.7473e-05, 1.7531e-05, 1.3946e-05, 3.5185e-05, 2.8750e-05,\n",
            "        1.1708e-05, 1.5301e-05, 1.7845e-05, 1.3654e-05, 5.4799e-05, 1.4541e-05,\n",
            "        2.1012e-05, 3.0155e-05, 5.9062e-06, 8.2086e-06, 1.8747e-05, 4.1847e-05,\n",
            "        9.6700e-06, 1.7964e-05, 1.4844e-05, 1.4619e-05, 3.0407e-05, 2.1671e-05,\n",
            "        2.8080e-05, 1.8943e-05, 4.1040e-06, 1.6279e-05, 1.7598e-05, 2.1738e-05,\n",
            "        1.5043e-05, 8.7795e-06, 7.7322e-06, 1.0247e-05, 3.3558e-05, 1.4045e-05,\n",
            "        1.5260e-05, 1.0504e-05, 2.4395e-05, 7.2603e-06, 2.3024e-05, 3.6498e-05,\n",
            "        6.3686e-06, 8.3904e-06, 1.1489e-05, 1.6684e-05, 8.2122e-06, 7.3346e-06,\n",
            "        1.7020e-05, 1.3606e-05, 1.0223e-05, 9.2187e-06, 8.8084e-06, 1.0283e-05,\n",
            "        4.5752e-06, 3.8138e-06, 4.0080e-05, 8.2313e-06, 1.6678e-05, 2.1501e-05,\n",
            "        3.1908e-05, 1.5459e-05, 3.5853e-05, 1.1873e-05, 2.7772e-05, 1.3308e-05,\n",
            "        6.6405e-06, 7.4611e-05, 1.0962e-05, 7.6544e-06, 4.1684e-05, 7.8274e-06,\n",
            "        1.7613e-05, 7.5710e-06, 2.1333e-05, 4.2397e-05, 1.7090e-05, 1.3629e-05,\n",
            "        1.8244e-05, 4.4653e-06, 7.7112e-05, 8.0509e-06, 1.0524e-05, 4.0827e-05,\n",
            "        2.0853e-05, 2.0898e-05, 3.5320e-05, 7.2259e-05, 3.3029e-05, 1.6842e-05,\n",
            "        3.4391e-06, 2.2082e-05, 5.8895e-05, 8.9084e-06, 2.7891e-05, 2.1940e-05,\n",
            "        1.2625e-05, 1.9812e-05, 1.7730e-05, 1.3376e-05, 8.9296e-06, 1.7879e-05,\n",
            "        2.5897e-05, 4.8600e-06, 7.4846e-06, 1.8515e-05, 2.4884e-05, 2.8516e-05,\n",
            "        9.3757e-06, 1.1566e-05, 1.5036e-05, 8.4250e-06, 2.4185e-05, 3.5165e-05,\n",
            "        3.1746e-05, 1.2895e-05, 1.7137e-05, 5.4822e-05, 6.4239e-06, 3.5337e-05,\n",
            "        3.9793e-05, 1.0538e-05, 2.1348e-05, 3.1569e-05, 3.7572e-05, 2.5513e-05,\n",
            "        1.7718e-05, 2.4876e-05, 1.6158e-05, 2.4638e-05, 1.9813e-05, 1.6788e-05,\n",
            "        2.9668e-05, 1.7183e-05, 2.1363e-05, 1.7363e-05, 2.5277e-05, 1.6654e-05,\n",
            "        3.6772e-05, 1.2167e-05, 1.2762e-05, 1.6654e-05, 1.4937e-05, 1.4741e-05,\n",
            "        2.1206e-05, 1.2410e-05, 2.1546e-05, 4.0832e-05, 1.0972e-05, 4.2867e-06,\n",
            "        2.0955e-05, 1.0037e-05, 6.7363e-05, 3.8995e-05, 8.4601e-06, 1.2769e-05,\n",
            "        2.8060e-05, 9.3079e-06, 1.4956e-05, 6.5231e-06, 5.5716e-06, 1.1619e-05,\n",
            "        7.5368e-06, 4.3650e-05, 2.0043e-05, 5.7119e-06, 6.0347e-06, 5.0213e-06,\n",
            "        2.9980e-05, 6.8605e-05, 3.6459e-05, 2.2301e-05, 6.4860e-06, 4.6253e-06,\n",
            "        2.3458e-05, 4.5730e-05, 3.0053e-06, 2.3565e-05, 1.8375e-05, 8.5421e-05,\n",
            "        1.3112e-05, 1.1976e-05, 2.3439e-05, 6.0501e-06, 2.1103e-05, 1.0751e-05,\n",
            "        1.4768e-05, 2.2875e-05, 1.9278e-05, 4.1115e-05, 3.3092e-05, 1.0232e-05,\n",
            "        2.7779e-05, 1.3867e-05, 4.1089e-06, 2.2783e-05, 1.1744e-05, 8.7706e-06,\n",
            "        1.0019e-05, 1.5616e-05, 1.6477e-05, 1.6362e-05, 6.1433e-05, 1.0712e-05,\n",
            "        6.4744e-06, 1.2353e-05, 1.3029e-05, 3.0918e-05, 1.3564e-05, 2.7310e-05,\n",
            "        6.5884e-06, 1.5234e-05, 7.6531e-06, 1.3352e-05, 2.3841e-05, 8.9773e-06,\n",
            "        7.5869e-05, 4.7989e-05, 1.2907e-05, 2.4119e-05, 7.4266e-06, 8.8220e-06,\n",
            "        5.6912e-05, 9.4332e-06, 3.5632e-05, 3.6352e-05, 7.9009e-06, 1.1817e-05,\n",
            "        8.5145e-06, 1.9907e-05, 3.0772e-05, 1.1324e-05, 2.2677e-05, 2.2447e-05,\n",
            "        5.2012e-05, 1.8680e-05, 1.9599e-05, 7.0228e-06, 1.2401e-05, 1.1178e-05,\n",
            "        5.8770e-05, 1.8823e-05, 2.1845e-05, 3.5288e-05, 1.2764e-05, 1.6048e-05,\n",
            "        1.9183e-05, 1.2502e-05, 1.6709e-05, 2.2543e-05, 2.8344e-05, 6.8301e-06,\n",
            "        2.2885e-05, 7.2863e-06, 6.6729e-06, 1.0581e-05, 3.2046e-05, 1.9790e-05,\n",
            "        1.0968e-05, 8.5068e-06, 2.5192e-05, 3.4127e-05, 1.2651e-05, 1.9476e-05,\n",
            "        1.5549e-05, 1.0861e-05, 4.4529e-05, 1.2785e-05, 7.7976e-05, 4.9741e-05,\n",
            "        8.4785e-06, 1.5392e-05, 1.8421e-05, 8.3880e-06, 1.2473e-05, 1.6024e-05,\n",
            "        6.8786e-05, 2.2625e-05, 8.3760e-06, 6.4857e-06, 3.1457e-05, 6.1909e-06,\n",
            "        2.2653e-05, 1.2057e-05, 2.4262e-05, 1.2552e-05, 2.2288e-05, 1.3961e-05,\n",
            "        1.8425e-05, 2.0790e-05, 1.3742e-05, 1.5226e-05, 7.2475e-06, 8.3471e-05,\n",
            "        2.1165e-05, 9.5989e-06, 2.0172e-05, 1.0530e-05, 7.4014e-06, 1.6744e-05,\n",
            "        2.7631e-05, 3.2986e-05, 4.3777e-05, 2.9364e-05, 7.6328e-06, 7.3708e-06,\n",
            "        1.2274e-05, 4.4195e-05, 2.3299e-05, 1.8166e-05, 5.6733e-05, 3.0866e-05,\n",
            "        5.0915e-05, 6.3491e-05, 1.7290e-05, 3.8103e-05, 1.1363e-05, 3.8081e-05,\n",
            "        1.0304e-05, 1.8947e-05, 4.0990e-05, 5.1891e-05, 3.7275e-05, 6.0860e-06,\n",
            "        4.3472e-06, 3.3944e-05, 1.1050e-05, 1.4573e-05, 1.1636e-05, 6.0866e-06,\n",
            "        8.9202e-06, 1.9071e-05, 1.7847e-05, 2.2067e-05, 4.0319e-05, 1.5957e-05,\n",
            "        1.7190e-05, 1.2611e-05, 2.9913e-05, 6.9605e-05, 3.0070e-05, 3.7081e-05,\n",
            "        2.5093e-05, 2.8865e-05, 2.3442e-05, 1.5619e-05, 3.5202e-05, 1.8324e-05,\n",
            "        6.7712e-05, 2.5838e-05, 4.6007e-05, 1.7528e-05, 2.2499e-05, 4.7409e-05,\n",
            "        1.0393e-04, 2.3742e-05, 4.4047e-05, 6.3359e-06, 1.3457e-05, 2.0588e-05,\n",
            "        1.1749e-05, 1.1546e-05, 2.4948e-05, 2.5005e-05])\n"
          ]
        }
      ],
      "source": [
        "# sample execution (requires torchvision)\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "input_image = Image.open(filename)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "# move the input and model to GPU for speed if available\n",
        "input_batch = input_batch.to('mps')\n",
        "model.to('mps')\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)\n",
        "# Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n",
        "print(output[0])\n",
        "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
        "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "print(probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZnviuDVnS4c",
        "outputId": "ef6b2ae5-bb4d-482a-a91a-2618caadf196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-03-01 14:47:29--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8001::154, 2606:50c0:8003::154, 2606:50c0:8000::154, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8001::154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10472 (10K) [text/plain]\n",
            "Saving to: ‘imagenet_classes.txt’\n",
            "\n",
            "imagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2024-03-01 14:47:30 (1.25 MB/s) - ‘imagenet_classes.txt’ saved [10472/10472]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download ImageNet labels\n",
        "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7jz_Fn9nV26",
        "outputId": "15e56913-70be-4c1c-9e4c-2ecdaa9b6359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Samoyed 0.9378381967544556\n",
            "Pomeranian 0.008283459581434727\n",
            "Great Pyrenees 0.005603065248578787\n",
            "Arctic fox 0.00552778597921133\n",
            "white wolf 0.004741043783724308\n"
          ]
        }
      ],
      "source": [
        "# Read the categories\n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "# Show top categories per image\n",
        "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "for i in range(top5_prob.size(0)):\n",
        "    print(categories[top5_catid[i]], top5_prob[i].item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
